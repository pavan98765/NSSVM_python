{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e315bb73",
   "metadata": {
    "id": "e315bb73"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import scipy.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e5bfc3",
   "metadata": {
    "id": "d3e5bfc3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "from time import time\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.io\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from scipy.sparse import diags, issparse\n",
    "def NSSVM(X, y, pars=None):\n",
    "    import numpy as np\n",
    "    import scipy.sparse as sp\n",
    "\n",
    "    def Fnorm(var):\n",
    "        return np.linalg.norm(var)**2\n",
    "\n",
    "    def GetParameters(m, n):\n",
    "        maxit = 1e3\n",
    "        alpha = np.zeros(m)\n",
    "        tune = 0\n",
    "        disp = 1\n",
    "        tol = 1e-6\n",
    "        eta = min(1/m, 1e-4)\n",
    "        if max(m, n) < 1e4:\n",
    "            beta = 1\n",
    "        elif m <= 5e5:\n",
    "            beta = 0.05\n",
    "        elif m <= 1e8:\n",
    "            beta = 10\n",
    "        s0 = np.ceil(beta * n * (np.log2(m/n))**2)\n",
    "        if m > 5e6:\n",
    "            C = np.log10(m)\n",
    "        else:\n",
    "            C = 1/2\n",
    "        c = C/100\n",
    "        return maxit, alpha, tune, disp, tol, eta, s0, C, c\n",
    "\n",
    "    def my_cg(Q, y, E, b, cgtol, cgit, x):\n",
    "        r = b\n",
    "        e = np.sum(r*r)\n",
    "        t = e\n",
    "        for i in range(cgit):\n",
    "            if e < cgtol*t:\n",
    "                break\n",
    "            if i == 0:\n",
    "                p = r\n",
    "            else:\n",
    "                p = r + (e/e0)*p\n",
    "            p1 = p[:-1]\n",
    "            w = np.concatenate((((Q.dot(p1)).dot(Q.T)).T + E*p1 + p[-1]*y, np.sum(y*p1)))\n",
    "            a = e/np.sum(p*w)\n",
    "            x = x + a*p\n",
    "            r = r - a*w\n",
    "            e0 = e\n",
    "            e = np.sum(r*r)\n",
    "        return x\n",
    "\n",
    "    if pars is None:\n",
    "        pars = {}\n",
    "\n",
    "    t0 = 0\n",
    "    m, n = X.shape\n",
    "\n",
    "    if sp.issparse(X) and sp.issparse(X) and sp.issparse(X)/m/n > 0.1:\n",
    "        X = X.toarray()\n",
    "\n",
    "    # if n < 3e4:\n",
    "    #     Qt = y*X\n",
    "    # else:\n",
    "    #     Qt = sp.diags(y, 0, m, m)*X\n",
    "\n",
    "    if y.ndim != 1 or y.shape[0] != m:\n",
    "        raise ValueError(\"y must be a 1D array with the same number of elements as rows in X\")\n",
    "\n",
    "    if n < 3e4:\n",
    "        Qt = y[:, np.newaxis] * X\n",
    "    else:\n",
    "        if y.shape[0] != X.shape[0]:  # Ensuring y and X have matching dimensions\n",
    "            raise ValueError(\"Mismatched dimensions between y and X: {} vs {}\".format(y.shape[0], X.shape[0]))\n",
    "        Qt = sp.diags(y, 0, shape=(m, m)) * X\n",
    "\n",
    "\n",
    "    Q = Qt.T\n",
    "    maxit, alpha, tune, disp, tol, eta, s0, C, c = GetParameters(m, n)\n",
    "\n",
    "    if 'maxit' in pars:\n",
    "        maxit = pars['maxit']\n",
    "    if 'alpha' in pars:\n",
    "        alpha = pars['alpha']\n",
    "    if 'disp' in pars:\n",
    "        disp = pars['disp']\n",
    "    if 'tune' in pars:\n",
    "        tune = pars['tune']\n",
    "    if 'tol' in pars:\n",
    "        tol = pars['tol']\n",
    "    if 'eta' in pars:\n",
    "        eta = pars['eta']\n",
    "    if 's0' in pars:\n",
    "        s0 = min(m, int(pars['s0']))\n",
    "    if 'C' in pars:\n",
    "        C = pars['C']\n",
    "    if 'c' in pars:\n",
    "        c = pars['c']\n",
    "\n",
    "    T1 = np.where(y == 1)[0]\n",
    "    nT1 = len(T1)\n",
    "    T2 = np.where(y == -1)[0]\n",
    "    nT2 = len(T2)\n",
    "\n",
    "    if nT1 < s0:\n",
    "        T = np.concatenate((T1, T2[:int(s0 - nT1)]))  # Cast to int\n",
    "    elif nT2 < s0:\n",
    "        T = np.concatenate((T1[:int(s0 - nT2)], T2))  # Cast to int\n",
    "    else:\n",
    "        T = np.concatenate((T1[:int(np.ceil(s0 / 2))], T2[:int(s0 - np.ceil(s0 / 2))]))  # Ensure all indices are integers\n",
    "    T = np.sort(T[:int(s0)])\n",
    "    s = int(s0)\n",
    "    b = (nT1 >= nT2) - (nT1 < nT2)\n",
    "    bb = b\n",
    "    w = np.zeros(n)\n",
    "    gz = -np.ones(m)\n",
    "    ERR = np.zeros(maxit)\n",
    "    ACC = np.zeros(maxit)\n",
    "    ACC[0] = 1 - np.count_nonzero(np.sign(b)-y)/m\n",
    "    ET = np.ones(s)/C\n",
    "\n",
    "    maxACC = 0\n",
    "    flag = 1\n",
    "    j = 1\n",
    "    r = 1.1\n",
    "    count = 1\n",
    "    count0 = 2\n",
    "    iter0 = -1\n",
    "\n",
    "    if disp:\n",
    "        print('Run NSSVM ......')\n",
    "        print('------------------------------------------')\n",
    "        print('  Iter          Error           Accuracy  ')\n",
    "        print('------------------------------------------')\n",
    "\n",
    "    for iter in range(1, maxit+1):\n",
    "        if iter == 1 or flag:\n",
    "            QT = Q[:, T]\n",
    "            QtT = Qt[T, :]\n",
    "            yT = y[T]\n",
    "            ytT = yT.T\n",
    "\n",
    "        alphaT = alpha[T]\n",
    "        gzT = -gz[T]\n",
    "        alyT = -ytT.dot(alphaT)\n",
    "\n",
    "        err = (np.abs(Fnorm(alpha)-Fnorm(alphaT)) + Fnorm(gzT) + alyT**2)/(m*n)\n",
    "        ERR[iter-1] = np.sqrt(err)\n",
    "\n",
    "        if tune and iter < 30 and m <= 1e8:\n",
    "            stop1 = (iter > 5 and err < tol*s*np.log2(m)/100)\n",
    "            stop2 = (s != s0 and np.abs(ACC[iter-1] - np.max(ACC[:iter-1])) <= 1e-4)\n",
    "            stop3 = (s != s0 and iter > 10 and np.max(ACC[iter-5:iter]) < maxACC)\n",
    "            stop4 = (count != count0+1 and ACC[iter] >= ACC[0])\n",
    "            stop = (stop1 and (stop2 or stop3) and stop4)\n",
    "        else:\n",
    "            stop1 = (err < tol*np.sqrt(s)*np.log10(m))\n",
    "            stop2 = (iter > 4 and np.std(ACC[iter-2:iter]) < 1e-4)\n",
    "            stop3 = (iter > 20 and np.abs(np.max(ACC[iter-8:iter]) - maxACC) <= 1e-4)\n",
    "            stop = (stop1 and stop2) or stop3\n",
    "\n",
    "        if disp:\n",
    "            print(f'  {iter:3d}          {err:6.2e}         {ACC[iter-1]:7.5f}')\n",
    "\n",
    "        if ACC[iter-1] > 0 and (ACC[iter-1] >= 0.99999 or stop):\n",
    "            break\n",
    "\n",
    "        ET0 = ET\n",
    "        ET = (alphaT >= 0)/C + (alphaT < 0)/c\n",
    "\n",
    "        if min(n, s) > 1e3:\n",
    "            d = my_cg(QT, yT, ET, np.concatenate((gzT, alyT)), 1e-10, 50, np.zeros(s+1))\n",
    "            dT = d[:s]\n",
    "            dend = d[-1]\n",
    "        else:\n",
    "            if s <= n:\n",
    "                if iter == 1 or flag:\n",
    "                    PTT0 = QtT.dot(QT)\n",
    "                PTT = PTT0 + sp.diags(ET, 0, (s, s))\n",
    "                d = np.linalg.solve(np.concatenate((np.concatenate((PTT, yT[:, np.newaxis]), axis=1), np.concatenate((ytT[:, np.newaxis], np.zeros((1, 1))), axis=1))), np.concatenate((gzT, alyT)))\n",
    "                dT = d[:s]\n",
    "                dend = d[-1]\n",
    "            else:\n",
    "                ETinv = 1/ET\n",
    "                flag1 = np.count_nonzero(ET0) != np.count_nonzero(ET)\n",
    "                flag2 = np.count_nonzero(ET0) == np.count_nonzero(ET) and np.count_nonzero(ET0-ET) == 0\n",
    "                if iter == 1 or flag or flag1 or not flag2:\n",
    "                    EQtT = sp.diags(ETinv, 0, (s, s)).dot(QtT)\n",
    "                    P0 = np.eye(n) + QT.dot(EQtT)\n",
    "                Ey = ETinv*yT\n",
    "                Hy = Ey - EQtT.dot(np.linalg.solve(P0, QT.dot(Ey)))\n",
    "                dend = (gzT.dot(Hy) - alyT)/(ytT.dot(Hy))\n",
    "                tem = ETinv*(gzT - dend*yT)\n",
    "                dT = tem - EQtT.dot(np.linalg.solve(P0, QT.dot(tem)))\n",
    "\n",
    "        alpha = np.zeros(m)\n",
    "        alphaT = alphaT + dT\n",
    "        alpha[T] = alphaT\n",
    "        b = b + dend\n",
    "\n",
    "        w = QT.dot(alphaT)\n",
    "        Qtw = Qt.dot(w)\n",
    "        tmp = y*Qtw\n",
    "\n",
    "        gz = Qtw - 1 + b*y\n",
    "        ET1 = (alphaT >= 0)/C + (alphaT < 0)/c\n",
    "        gz[T] = alphaT*ET1 + gz[T]\n",
    "\n",
    "        j = iter+1\n",
    "        ACC[j-1] = 1 - np.count_nonzero(np.sign(tmp+b)-y)/m\n",
    "\n",
    "        if m <= 1e7:\n",
    "            bb = np.mean(yT - tmp[T])\n",
    "            ACCb = 1 - np.count_nonzero(np.sign(tmp+bb)-y)/m\n",
    "            if ACC[j-1] >= ACCb:\n",
    "                bb = b\n",
    "            else:\n",
    "                ACC[j-1] = ACCb\n",
    "        else:\n",
    "            bb = b\n",
    "\n",
    "        if m < 6e6 and ACC[j-1] < 0.5:\n",
    "            opt = {'maxiter': 10*(m >= 1e6) + 20*(m < 1e6), 'disp': False}\n",
    "            b0 = minimize(lambda t: np.sum((np.sign(tmp+t[0])-y)**2), bb, options=opt).x[0]\n",
    "            acc0 = 1 - np.count_nonzero(np.sign(tmp+b0)-y)/m\n",
    "            if ACC[j-1] < acc0:\n",
    "                bb = b0\n",
    "                ACC[j-1] = acc0\n",
    "\n",
    "        if ACC[j-1] >= maxACC:\n",
    "            maxACC = ACC[j-1]\n",
    "            alpha0 = alpha.copy()\n",
    "            tmp0 = tmp.copy()\n",
    "            maxwb = np.concatenate((w, [bb]))\n",
    "\n",
    "        T0 = T.copy()\n",
    "        mark = 0\n",
    "        if tune and (err < tol or iter % 10 == 0) and iter > iter0+2 and count < 10:\n",
    "            count0 = count\n",
    "            count = count + 1\n",
    "            s = min(m, np.ceil(r*s))\n",
    "            iter0 = iter\n",
    "            if count > (m >= 1e6 or n < 3) + 1*(m < 1e6 and n >= 5):\n",
    "                alpha = np.zeros(m)\n",
    "                gz = -np.ones(m)\n",
    "                mark = 1\n",
    "        else:\n",
    "            count0 = count\n",
    "\n",
    "        if s != m:\n",
    "            if m < 5e8:\n",
    "              T = np.argsort(np.abs(alpha - eta * gz))[-s:]\n",
    "            else:\n",
    "              T = np.argsort(np.abs(alpha - eta * gz))[::-1][:s]\n",
    "            T = np.sort(T[:s])\n",
    "            if mark:\n",
    "                nT = np.count_nonzero(y[T] == 1)\n",
    "                if nT == s:\n",
    "                    if nT2 <= 0.75*s:\n",
    "                        T = np.concatenate((T[:s-np.ceil(nT2/2)], T2[:np.ceil(nT2/2)]))\n",
    "                    else:\n",
    "                        T = np.concatenate((T[:np.ceil(s/4)], T2[:s-np.ceil(s/4)]))\n",
    "                elif nT == 0:\n",
    "                    if nT1 <= 0.75*s:\n",
    "                        T = np.concatenate((T[:s-np.ceil(nT1/2)], T1[:np.ceil(nT1/2)]))\n",
    "                    else:\n",
    "                        T = np.concatenate((T[:np.ceil(s/4)], T1[:s-np.ceil(s/4)]))\n",
    "                T = np.sort(T[:s])\n",
    "        else:\n",
    "            T = np.arange(m)\n",
    "\n",
    "        flag = 1\n",
    "        flag3 = np.count_nonzero(T0) == s\n",
    "\n",
    "        if flag3:\n",
    "            flag3 = np.count_nonzero(T-T0) == 0\n",
    "\n",
    "        if flag3 or np.count_nonzero(T0) == m:\n",
    "            flag = 0\n",
    "            T = T0\n",
    "\n",
    "    wb = np.concatenate((w, [bb]))\n",
    "    acc = ACC[j-1]\n",
    "\n",
    "    if m <= 1e7 and iter > 1:\n",
    "        opt = {'maxiter': 20, 'disp': False}\n",
    "        b0 = minimize(lambda t: np.linalg.norm(np.sign(tmp0+t[0])-y), maxwb[-1], options=opt).x[0]\n",
    "        acc0 = 1 - np.count_nonzero(np.sign(tmp0+b0)-y)/m\n",
    "        if acc < acc0:\n",
    "            wb = np.concatenate((maxwb[:-1], [b0]))\n",
    "            acc = acc0\n",
    "\n",
    "    if acc < maxACC-1e-4:\n",
    "        alpha = alpha0.copy()\n",
    "        wb = maxwb.copy()\n",
    "        acc = maxACC\n",
    "\n",
    "    if disp:\n",
    "        print('------------------------------------------')\n",
    "\n",
    "    Out = {'s': s, 'w': wb, 'sv': s, 'ACC': acc, 'iter': iter, 'time': 0-t0, 'alpha': alpha}\n",
    "    return Out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SmsEK-fOshr2",
   "metadata": {
    "id": "SmsEK-fOshr2"
   },
   "source": [
    "## a5a.t dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d05SMWu0eoT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d05SMWu0eoT",
    "outputId": "ca1199c6-9df7-44f7-c7e9-81dceeda8652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run NSSVM ......\n",
      "------------------------------------------\n",
      "  Iter          Error           Accuracy  \n",
      "------------------------------------------\n",
      "    1          1.31e-04         0.75895\n",
      "    2          9.71e-02         0.79204\n",
      "    3          2.70e-02         0.75245\n",
      "    4          4.42e-03         0.75580\n",
      "    5          1.16e-02         0.76761\n",
      "    6          1.07e-02         0.75341\n",
      "    7          2.41e-02         0.75929\n",
      "    8          9.56e-03         0.74619\n",
      "    9          2.94e-03         0.71975\n",
      "   10          4.07e-03         0.75097\n",
      "   11          8.92e-05         0.74365\n",
      "   12          1.64e-04         0.75259\n",
      "   13          3.05e-06         0.75355\n",
      "   14          2.43e-06         0.75503\n",
      "   15          2.57e-06         0.75632\n",
      "   16          7.70e-06         0.75298\n",
      "   17          6.69e-06         0.75427\n",
      "   18          1.77e-06         0.75537\n",
      "   19          3.60e-09         0.76067\n",
      "   20          3.83e-30         0.76024\n",
      "   21          2.21e-20         0.76024\n",
      "------------------------------------------\n",
      "Training complete.\n",
      "Model weights: [ 6.36136778e-03 -4.44883886e-02 -2.02690596e-02  6.88049643e-04\n",
      "  5.45675708e-02  6.23470104e-02  1.79632825e-02  9.21461284e-02\n",
      "  3.01104484e-02  5.03441589e-03 -5.89195075e-02 -7.18804356e-15\n",
      " -4.55042362e-15  7.41216608e-03  4.42175100e-02 -5.83665906e-02\n",
      "  1.20884888e-02 -5.35933396e-03 -1.04598086e-02  2.33457087e-02\n",
      " -3.67286409e-02 -7.65909008e-03  7.41774086e-02  2.31772924e-02\n",
      " -5.00207067e-03 -4.41331000e-14 -5.49167261e-02 -6.13556856e-02\n",
      "  1.78161961e-02 -5.21605369e-02 -3.27155398e-02  6.77196584e-02\n",
      "  4.16340111e-02 -1.18843195e-14 -7.90704963e-02 -7.65909008e-03\n",
      "  2.33457087e-02  1.17237050e-02  4.01095278e-02  1.54387746e-01\n",
      "  1.90118443e-02 -1.46588210e-01 -6.83042081e-02 -2.17392876e-02\n",
      "  7.61770137e-03 -7.69344441e-15  5.74100442e-02 -5.19760923e-02\n",
      " -7.70271995e-02  9.10424509e-02  8.96198391e-02  1.37394709e-01\n",
      " -3.68833742e-02 -5.87229656e-03  5.49656891e-03 -4.35424948e-02\n",
      " -9.34088937e-02 -2.15646728e-14  5.40246936e-02 -6.13512062e-15\n",
      "  7.94156797e-02 -4.01510385e-02  5.45475240e-02 -7.20495047e-03\n",
      " -1.60780554e-02 -7.61194440e-02 -3.04982444e-03  3.40712921e-02\n",
      " -2.82803960e-02 -2.91973309e-02  1.44170035e-03 -4.20095882e-02\n",
      "  4.20095882e-02 -5.50350699e-02  5.50350699e-02 -3.81632170e-02\n",
      "  3.81632170e-02 -6.09016848e-02  5.20160715e-03 -2.39960775e-02\n",
      "  2.24726811e-02  6.75178078e-02 -2.80161483e-01 -9.12480811e-15\n",
      " -1.32402279e-02 -5.18533739e-02 -3.59736767e-02 -7.07904649e-02\n",
      " -7.03078004e-15 -2.24976288e-14 -6.07876386e-02 -9.66522869e-15\n",
      " -9.88596611e-02 -7.39504282e-02 -1.09687975e-01 -1.31060527e-14\n",
      " -7.53138329e-15 -1.11927007e-01 -5.02007034e-02 -1.30866455e-14\n",
      " -1.65018823e-14 -5.06691251e-02 -1.84769269e-01 -1.28648177e-14\n",
      " -8.66196221e-15 -1.25384729e-14 -1.57703711e-14 -9.66961971e-15\n",
      " -1.00166728e-14 -1.39594282e-14 -2.64411262e-02 -3.84102671e-02\n",
      " -6.19692015e-15 -1.29821284e-14 -1.02255444e-14 -6.58235402e-15\n",
      " -6.31520660e-15 -5.96425036e-15 -2.07154172e-14 -8.42018512e-15\n",
      " -1.12996635e-14 -7.96812703e-15 -2.68115066e-15 -1.18213031e+00]\n",
      "Final Training Accuracy: 79.2035186690252\n",
      "Testing Accuracy: 79.33078393881453\n",
      "Total iterations: 21\n",
      "Training time: 0.4509754180908203 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Load the dataset from the LIBSVM format file\n",
    "X, y = load_svmlight_file('./data/a5a.t')\n",
    "\n",
    "# Convert to dense format as many scikit-learn estimators expect dense format\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def predict_NSSVM(X, model_output):\n",
    "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
    "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
    "    b = model_output['w'][-1]\n",
    "    return np.sign(X.dot(w) + b)\n",
    "\n",
    "# Timing the NSSVM training\n",
    "start_time = time.time()\n",
    "\n",
    "# Run NSSVM on the training data\n",
    "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
    "\n",
    "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
    "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
    "\n",
    "# Calculate and print accuracies\n",
    "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
    "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(\"Model weights:\", model_output['w'])\n",
    "print(\"Final Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"Total iterations:\", model_output['iter'])\n",
    "print(\"Training time:\", elapsed_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HsJm4mVdO-2X",
   "metadata": {
    "id": "HsJm4mVdO-2X"
   },
   "source": [
    "# a6a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbDzVK6sOjhd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbDzVK6sOjhd",
    "outputId": "feb0d29c-c0f3-4fad-83a5-100b6f0110bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run NSSVM ......\n",
      "------------------------------------------\n",
      "  Iter          Error           Accuracy  \n",
      "------------------------------------------\n",
      "    1          1.49e-04         0.75756\n",
      "    2          9.29e-02         0.78368\n",
      "    3          3.48e-02         0.77595\n",
      "    4          1.15e-02         0.77571\n",
      "    5          2.41e-02         0.78187\n",
      "    6          2.91e-03         0.77894\n",
      "    7          3.34e-02         0.76933\n",
      "    8          2.57e-02         0.76025\n",
      "    9          3.13e-03         0.76992\n",
      "   10          7.63e-04         0.77929\n",
      "   11          2.09e-04         0.77864\n",
      "   12          4.53e-03         0.78022\n",
      "   13          2.06e-05         0.76863\n",
      "   14          5.20e-05         0.75996\n",
      "   15          1.32e-02         0.76593\n",
      "   16          1.05e-04         0.75638\n",
      "   17          8.69e-05         0.75574\n",
      "   18          7.73e-10         0.75539\n",
      "   19          2.78e-30         0.75545\n",
      "------------------------------------------\n",
      "Training complete.\n",
      "Model weights: [-5.57898627e-02 -7.23880726e-02  3.97736475e-02  9.91778925e-03\n",
      "  7.23976900e-02  1.64417032e-01  1.20674478e-01  3.80704455e-02\n",
      "  1.57865476e-01 -6.31784791e-03  1.02028184e-01  8.35941559e-15\n",
      "  5.61551673e-15  1.48543922e-02 -2.06740246e-02  8.61561461e-03\n",
      " -1.03304042e-02  7.51490997e-03  1.05978496e-01  7.12835963e-03\n",
      " -4.71294646e-02 -5.38099770e-02  4.14621618e-02 -3.63300163e-02\n",
      "  2.76757682e-02 -1.66097224e-02 -3.70636943e-02 -1.64337752e-02\n",
      "  2.69534247e-02  2.62997089e-14 -5.69297425e-02  2.70054461e-02\n",
      " -3.21257533e-02  1.20728080e-14 -9.11120665e-02 -5.38099770e-02\n",
      "  7.12835963e-03 -3.04603081e-03  1.24654756e-01  2.27882966e-01\n",
      " -1.87749984e-01 -4.69605984e-02 -8.70171475e-02 -1.40911631e-02\n",
      " -8.92493449e-02  1.76036642e-02  9.37111339e-02  6.75365144e-02\n",
      "  2.04748019e-02 -9.57426460e-03  9.94304179e-02  6.40223541e-02\n",
      "  2.09941648e-02  6.04096309e-02  1.04923820e-01 -6.40152988e-02\n",
      "  2.33164237e-03  1.61718922e-02  1.51453364e-01  7.41377446e-15\n",
      "  8.69605794e-02 -1.20961678e-01  2.17402341e-02  2.09943808e-02\n",
      " -2.49812879e-02  2.98973699e-02 -4.02332335e-02  5.22244965e-02\n",
      "  4.00121878e-04 -1.01546200e-01  4.96165970e-02 -3.04692725e-02\n",
      "  3.04692725e-02 -7.54318763e-02  7.54318763e-02  1.70831416e-02\n",
      " -1.70831416e-02 -2.64275453e-03  8.21674607e-03 -9.71834924e-03\n",
      "  5.59691953e-03  5.53003046e-03 -1.03637074e-01  6.84792934e-15\n",
      " -6.94454302e-02 -3.17256801e-02  2.16171874e-02 -3.23044443e-02\n",
      " -1.95828644e-02 -3.25937645e-02 -5.98285261e-02  9.67650439e-15\n",
      "  1.86760329e-14 -1.16323930e-01  1.78151764e-14  1.12817741e-14\n",
      "  4.98136688e-15 -6.80324494e-02  1.75059620e-14  1.36232171e-14\n",
      " -1.69582009e-02  1.33810064e-14 -1.29483278e-01  1.25229688e-14\n",
      "  8.36787237e-15  8.87441162e-15  1.54572535e-14  7.95088821e-15\n",
      "  1.14073247e-14  1.20591471e-14  1.26459173e-14  1.38159883e-14\n",
      "  1.49206867e-02 -8.00452342e-03  1.14864715e-14  6.20553955e-15\n",
      "  6.26820644e-15  9.14871477e-15  2.00867968e-14  2.19422615e-03\n",
      "  6.97302863e-03  7.20224661e-15  2.47577566e-15 -1.31014713e+00]\n",
      "Final Training Accuracy: 78.36808809746955\n",
      "Testing Accuracy: 78.77723120168658\n",
      "Total iterations: 19\n",
      "Training time: 0.362332820892334 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Load the dataset from the LIBSVM format file\n",
    "X, y = load_svmlight_file('./data/a6a.t')\n",
    "\n",
    "# Convert to dense format as many scikit-learn estimators expect dense format\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def predict_NSSVM(X, model_output):\n",
    "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
    "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
    "    b = model_output['w'][-1]\n",
    "    return np.sign(X.dot(w) + b)\n",
    "\n",
    "# Timing the NSSVM training\n",
    "start_time = time.time()\n",
    "\n",
    "# Run NSSVM on the training data\n",
    "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
    "\n",
    "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
    "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
    "\n",
    "# Calculate and print accuracies\n",
    "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
    "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(\"Model weights:\", model_output['w'])\n",
    "print(\"Final Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"Total iterations:\", model_output['iter'])\n",
    "print(\"Training time:\", elapsed_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BxMjnVzPO5ut",
   "metadata": {
    "id": "BxMjnVzPO5ut"
   },
   "source": [
    "# a7a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "QZWCOu7COjb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZWCOu7COjb7",
    "outputId": "3f9136df-dc82-4790-c6ff-29c4490ed10e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run NSSVM ......\n",
      "------------------------------------------\n",
      "  Iter          Error           Accuracy  \n",
      "------------------------------------------\n",
      "    1          1.73e-04         0.76420\n",
      "    2          1.52e-01         0.79465\n",
      "    3          3.48e-02         0.77172\n",
      "    4          6.98e-03         0.76830\n",
      "    5          1.68e-02         0.77734\n",
      "    6          5.76e-03         0.76974\n",
      "    7          1.31e-02         0.77529\n",
      "    8          1.73e-03         0.78083\n",
      "    9          3.88e-04         0.78698\n",
      "   10          4.28e-05         0.78600\n",
      "   11          4.23e-04         0.77278\n",
      "   12          3.04e-06         0.77491\n",
      "   13          2.87e-06         0.77635\n",
      "   14          8.19e-06         0.77248\n",
      "   15          2.79e-06         0.77339\n",
      "   16          5.01e-06         0.77628\n",
      "   17          5.09e-09         0.77423\n",
      "   18          4.65e-30         0.77392\n",
      "   19          7.82e-31         0.77392\n",
      "------------------------------------------\n",
      "Training complete.\n",
      "Model weights: [-4.84215209e-02 -3.44054106e-02 -7.38284447e-03  9.57266447e-03\n",
      "  7.65779809e-02  1.62790149e-01  1.04294745e-01  9.34726329e-02\n",
      "  3.67889077e-03  5.04161290e-02  2.35697020e-02 -1.22124533e-15\n",
      " -5.98479599e-16  1.05243946e-02 -3.68645121e-02 -3.70966650e-02\n",
      "  2.96543202e-02  3.37955770e-02  2.04166004e-02  6.32416478e-03\n",
      "  3.40511101e-02 -5.94594511e-02  6.01568582e-02 -4.39584599e-02\n",
      "  7.01519588e-02 -6.19834667e-02  8.87208676e-02 -1.27353642e-02\n",
      "  6.59687679e-02 -2.99760217e-15 -1.01827636e-01 -3.88835825e-02\n",
      " -5.17720826e-03 -1.65145675e-15 -2.29090083e-02 -5.94594511e-02\n",
      "  6.32416478e-03  2.48121660e-02  6.09840035e-02 -2.11589388e-02\n",
      "  4.40379708e-03 -2.68347845e-02  2.01288260e-02  1.01428285e-01\n",
      " -4.23966418e-15  2.41672512e-02  3.66778619e-03  6.06754511e-02\n",
      "  2.38569382e-02  5.44048436e-02  1.16353855e-01  1.58201070e-01\n",
      " -3.13260013e-02 -1.02088103e-01  1.06030218e-01 -6.91843506e-02\n",
      " -4.18374065e-03 -5.48866508e-15  7.85971250e-02 -1.21951060e-15\n",
      "  8.40458927e-02 -1.45095601e-01  2.72749538e-01 -5.65522106e-02\n",
      " -1.13871639e-01 -1.78004029e-01 -1.56397996e-02  9.83340840e-02\n",
      " -5.27007463e-02 -1.63857933e-02 -1.64342972e-02 -1.03650469e-02\n",
      "  1.03650469e-02 -4.02635067e-02  4.02635067e-02 -3.80734724e-02\n",
      "  3.80734724e-02 -1.18549982e-01  4.61537773e-03  5.83153560e-03\n",
      "  6.34072358e-02  5.70237666e-02  1.46788383e-01 -3.88578059e-16\n",
      " -7.14977056e-02 -1.22124533e-15 -2.55698240e-15  5.34621964e-02\n",
      " -5.55111512e-16 -1.05863746e-02  2.20866744e-02 -1.30451205e-15\n",
      " -3.80598331e-15  3.99834742e-02 -7.15761311e-02  5.71147204e-02\n",
      " -4.60569083e-16  1.55102035e-02 -9.61036806e-16 -1.72951931e-15\n",
      " -8.31963558e-04 -1.94809446e-15 -6.08092717e-02  1.33250313e-02\n",
      " -1.26808286e-15 -8.51749227e-16 -2.55698240e-15 -1.13624388e-15\n",
      " -1.20042865e-15  1.88512787e-02  3.32163545e-02 -2.97331604e-15\n",
      " -2.72351586e-16 -1.22818422e-15 -9.26613433e-03 -5.40366363e-16\n",
      " -8.37871439e-16 -7.44196371e-16 -1.89084859e-15 -6.27969898e-16\n",
      " -1.22471477e-15 -1.27675648e-15  9.97465999e-17 -1.29305064e+00]\n",
      "Final Training Accuracy: 79.46537059538275\n",
      "Testing Accuracy: 78.25690859398725\n",
      "Total iterations: 19\n",
      "Training time: 0.3532602787017822 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Load the dataset from the LIBSVM format file\n",
    "X, y = load_svmlight_file('./data/a7a.t')\n",
    "\n",
    "# Convert to dense format as many scikit-learn estimators expect dense format\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def predict_NSSVM(X, model_output):\n",
    "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
    "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
    "    b = model_output['w'][-1]\n",
    "    return np.sign(X.dot(w) + b)\n",
    "\n",
    "# Timing the NSSVM training\n",
    "start_time = time.time()\n",
    "\n",
    "# Run NSSVM on the training data\n",
    "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
    "\n",
    "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
    "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
    "\n",
    "# Calculate and print accuracies\n",
    "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
    "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(\"Model weights:\", model_output['w'])\n",
    "print(\"Final Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"Total iterations:\", model_output['iter'])\n",
    "print(\"Training time:\", elapsed_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8sc8Z_mWgtQk",
   "metadata": {
    "id": "8sc8Z_mWgtQk"
   },
   "source": [
    "# a8a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5DdZflDdf9ki",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5DdZflDdf9ki",
    "outputId": "b09e26e8-cfc4-4c6b-e1e6-3084e44852ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run NSSVM ......\n",
      "------------------------------------------\n",
      "  Iter          Error           Accuracy  \n",
      "------------------------------------------\n",
      "    1          4.59e-03         0.76026\n",
      "    2          2.17e+00         0.82691\n",
      "    3          8.37e-01         0.82970\n",
      "    4          1.11e-01         0.83147\n",
      "    5          7.65e-02         0.82970\n",
      "    6          9.41e-01         0.83084\n",
      "    7          6.45e-02         0.83996\n",
      "    8          6.70e-01         0.84136\n",
      "    9          2.23e-02         0.84187\n",
      "   10          2.87e-01         0.84326\n",
      "   11          2.21e-01         0.84453\n",
      "   12          5.11e-02         0.84503\n",
      "   13          1.23e-01         0.84415\n",
      "   14          2.48e-02         0.84503\n",
      "   15          5.79e-03         0.84579\n",
      "   16          1.54e-01         0.84503\n",
      "   17          2.95e-02         0.84554\n",
      "   18          5.58e-02         0.84554\n",
      "   19          2.75e-26         0.84592\n",
      "   20          4.72e-19         0.84592\n",
      "------------------------------------------\n",
      "Training complete.\n",
      "Model weights: [-1.04143797e-01 -6.13571653e-02  3.53558631e-02  7.02103474e-02\n",
      "  5.54895421e-02  2.24959787e-02 -2.06075451e-02  1.40378558e-02\n",
      "  2.91607295e-02 -8.27883252e-03 -8.00628892e-03 -8.65973959e-15\n",
      "  1.38340830e-02 -1.27385851e-02 -7.93622451e-03  1.47891861e-02\n",
      " -3.79782754e-03  9.63514496e-03  2.80215521e-02  5.93753615e-04\n",
      " -2.35312393e-02 -1.70143782e-02  3.98245820e-02  1.59693342e-02\n",
      "  3.40514764e-03 -2.52058674e-02 -4.35399305e-02  7.16034513e-03\n",
      "  3.02534022e-02 -3.26438785e-02 -3.92529397e-02  3.84392229e-02\n",
      " -5.59910144e-03 -1.27702656e-02 -6.76159735e-02 -1.70143782e-02\n",
      "  5.93753615e-04  1.34455739e-02  6.19369475e-02  1.45653503e-01\n",
      " -4.31928809e-02 -8.42100359e-02 -4.31047154e-02 -7.22062535e-03\n",
      " -9.17218541e-02  3.91647475e-03  1.97623421e-02  1.88534342e-02\n",
      " -1.05707315e-01  3.61677992e-02  8.15788056e-02  5.37525427e-02\n",
      " -3.79996833e-02 -3.53975088e-02  1.15249810e-02 -5.93637176e-02\n",
      " -1.27277464e-02 -7.41788616e-02  3.60698025e-02 -1.12410081e-14\n",
      "  1.13300343e-01 -1.15827899e-01  2.81429126e-02  2.18014998e-02\n",
      " -2.47782215e-03 -1.66238119e-02  1.33386158e-02  1.62167286e-03\n",
      " -3.80912478e-02  1.22177168e-02 -8.45946358e-03 -6.80755879e-02\n",
      "  6.80755879e-02 -7.26294461e-02  7.26294461e-02 -3.40644540e-02\n",
      "  3.40644540e-02 -1.09092356e-01  7.95354905e-04  9.21473412e-03\n",
      "  2.11140349e-02  7.48639015e-02  1.66871096e-02  4.62161893e-04\n",
      "  1.03094238e-02  8.89728357e-03 -4.63321378e-03 -5.04765824e-04\n",
      " -1.65491457e-02  8.85788828e-03 -9.72718197e-03 -1.26619793e-02\n",
      " -1.38976876e-02  6.49145430e-04  1.75502534e-02 -1.11561229e-03\n",
      "  1.09183496e-14  4.33987771e-03  1.64818387e-02  3.39184068e-04\n",
      " -2.89217025e-02 -4.76196022e-03 -3.24072424e-02  5.27516114e-03\n",
      "  1.39382347e-02  1.41417641e-02 -1.63017366e-02 -2.53339016e-14\n",
      " -2.76435926e-02  2.87026943e-03 -5.42195236e-02 -5.42191637e-02\n",
      " -1.12687637e-14  2.99276760e-02 -8.67361738e-16 -1.06676131e-02\n",
      "  4.71844785e-15 -1.33055769e-02 -5.39944925e-03 -6.05422010e-03\n",
      " -3.56933417e-02  1.33904415e-02 -5.40814232e-01]\n",
      "Final Training Accuracy: 84.59199189052204\n",
      "Testing Accuracy: 83.98378104409528\n",
      "Total iterations: 20\n",
      "Training time: 0.4941985607147217 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Load the dataset from the LIBSVM format file\n",
    "X, y = load_svmlight_file('./data/a8a.t')\n",
    "\n",
    "# Convert to dense format as many scikit-learn estimators expect dense format\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def predict_NSSVM(X, model_output):\n",
    "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
    "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
    "    b = model_output['w'][-1]\n",
    "    return np.sign(X.dot(w) + b)\n",
    "\n",
    "# Timing the NSSVM training\n",
    "start_time = time.time()\n",
    "\n",
    "# Run NSSVM on the training data\n",
    "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
    "\n",
    "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
    "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
    "\n",
    "# Calculate and print accuracies\n",
    "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
    "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(\"Model weights:\", model_output['w'])\n",
    "print(\"Final Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"Total iterations:\", model_output['iter'])\n",
    "print(\"Training time:\", elapsed_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czpW4K9CqbSH",
   "metadata": {
    "id": "czpW4K9CqbSH"
   },
   "source": [
    "# a9a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ElWyp7wkhbQx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElWyp7wkhbQx",
    "outputId": "286f3bad-a9c5-44f0-9390-79952a45f864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run NSSVM ......\n",
      "------------------------------------------\n",
      "  Iter          Error           Accuracy  \n",
      "------------------------------------------\n",
      "    1          1.74e-04         0.76205\n",
      "    2          1.18e-01         0.79284\n",
      "    3          2.39e-02         0.76751\n",
      "    4          4.17e-03         0.78025\n",
      "    5          1.24e-03         0.77019\n",
      "    6          2.29e-04         0.75653\n",
      "    7          6.80e-04         0.73887\n",
      "    8          3.89e-05         0.74209\n",
      "    9          7.24e-06         0.73618\n",
      "   10          1.42e-07         0.75660\n",
      "   11          5.25e-30         0.75660\n",
      "------------------------------------------\n",
      "Training complete.\n",
      "Model weights: [-1.79553699e-01 -1.72668294e-02  5.93434124e-02  7.82718098e-02\n",
      "  5.42774838e-02  5.93670568e-02 -3.99475155e-02  6.75545491e-02\n",
      "  4.16260846e-02 -1.03886858e-03 -3.01977471e-02  1.53609764e-15\n",
      "  1.31925720e-15  2.15207058e-03  3.05491849e-02 -6.22002905e-03\n",
      " -3.60969062e-03 -2.30474348e-02  3.14095589e-02 -1.51488283e-02\n",
      " -2.09512919e-02 -2.34427681e-02  1.45799251e-02  5.69906199e-03\n",
      " -1.26830927e-02  7.77036865e-03 -2.73974289e-02  3.88209518e-03\n",
      "  5.75937683e-02  7.39339145e-15 -1.60234161e-02  9.06346176e-03\n",
      "  1.51198498e-14  4.81212292e-15 -2.66707109e-02 -2.34427681e-02\n",
      " -1.51488283e-02 -5.74485695e-03  6.42978036e-02  2.07472673e-01\n",
      " -1.12666965e-01 -1.38031107e-01  6.57445626e-03 -4.15124572e-02\n",
      "  5.74253364e-02  3.43648721e-15  4.98974953e-02  5.19148012e-03\n",
      " -1.14352445e-01  6.08102063e-02  1.19767730e-01  1.21888238e-01\n",
      " -1.76920909e-02 -1.42984279e-01  2.03729089e-02  1.78330646e-02\n",
      " -7.99834437e-02  1.04569131e-14  1.04053515e-03  1.38474301e-15\n",
      " -1.87183523e-02  8.14873298e-02 -5.00788007e-02  1.60450395e-04\n",
      "  1.05456021e-02 -8.73405975e-03  2.10983551e-02  6.66517723e-02\n",
      " -2.79980564e-02  3.73042098e-04 -5.45086289e-02 -5.54565738e-02\n",
      "  5.54565738e-02 -6.73800177e-02  6.73800177e-02 -5.54763073e-03\n",
      "  5.54763073e-03 -3.26962915e-02 -9.93562111e-04 -5.78715742e-03\n",
      "  4.23130577e-02  9.72826317e-03  3.03863028e-01  3.00280634e-15\n",
      "  5.57540125e-15  6.77582990e-15  1.02597999e-01  9.61274935e-02\n",
      "  2.29850861e-15  7.97625854e-15  4.74620343e-15  3.42607887e-15\n",
      "  6.65613398e-15  5.24233434e-15  5.98479599e-15  2.89872293e-15\n",
      "  2.28116137e-15  3.11016342e-02  8.39430665e-02 -3.70608788e-03\n",
      "  4.43915738e-15  3.62383734e-15  5.07049283e-02  5.61529989e-15\n",
      "  6.19621257e-02  2.40345938e-15  8.70992836e-03  2.89872293e-15\n",
      "  5.74713888e-15  3.48159002e-15  7.16267323e-15  4.83467433e-15\n",
      "  2.07386192e-15  5.82520143e-15  3.69843045e-15  2.77035339e-15\n",
      "  3.94302646e-15  3.13898213e-15  6.49827414e-15  3.34975103e-15\n",
      "  2.94452923e-03  3.28036209e-15 -1.30907283e+00]\n",
      "Final Training Accuracy: 79.28439803439802\n",
      "Testing Accuracy: 79.82806263432607\n",
      "Total iterations: 11\n",
      "Training time: 0.18745875358581543 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Load the dataset from the LIBSVM format file\n",
    "X, y = load_svmlight_file('./data/a9a.t')\n",
    "\n",
    "# Convert to dense format as many scikit-learn estimators expect dense format\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def predict_NSSVM(X, model_output):\n",
    "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
    "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
    "    b = model_output['w'][-1]\n",
    "    return np.sign(X.dot(w) + b)\n",
    "\n",
    "# Timing the NSSVM training\n",
    "start_time = time.time()\n",
    "\n",
    "# Run NSSVM on the training data\n",
    "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
    "\n",
    "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
    "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
    "\n",
    "# Calculate and print accuracies\n",
    "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
    "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(\"Model weights:\", model_output['w'])\n",
    "print(\"Final Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"Total iterations:\", model_output['iter'])\n",
    "print(\"Training time:\", elapsed_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6nbjM0Cog1e",
   "metadata": {
    "id": "c6nbjM0Cog1e"
   },
   "source": [
    "## sonar, mines vs rocks dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "RJnzTaofoShS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJnzTaofoShS",
    "outputId": "c4bf13e2-6429-407b-b239-fc1908fae395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run NSSVM ......\n",
      "------------------------------------------\n",
      "  Iter          Error           Accuracy  \n",
      "------------------------------------------\n",
      "    1          1.31e-02         0.51205\n",
      "    2          1.53e+01         0.87952\n",
      "    3          4.90e+00         0.90964\n",
      "    4          1.24e+00         0.92771\n",
      "    5          6.46e-01         0.90361\n",
      "    6          1.06e+00         0.89157\n",
      "    7          5.55e-01         0.92169\n",
      "    8          3.64e-02         0.92771\n",
      "    9          1.05e+00         0.90964\n",
      "   10          5.18e-01         0.93976\n",
      "   11          2.42e-02         0.94578\n",
      "   12          5.99e-04         0.93976\n",
      "   13          7.49e-04         0.93373\n",
      "   14          1.78e-02         0.93976\n",
      "   15          9.58e-01         0.92771\n",
      "   16          1.89e-02         0.96988\n",
      "   17          6.89e-30         0.96988\n",
      "------------------------------------------\n",
      "Training complete.\n",
      "Model weights: [ 0.28884869  0.08075067 -0.58507656  0.63855408 -0.1712619   0.07367058\n",
      " -0.18801916 -0.31676877  0.38202038 -0.09807146  0.22773917  0.56728722\n",
      " -0.25864816 -0.25935134  0.13452374 -0.43147254  0.04489038  0.30535472\n",
      " -0.18815243  0.33601393 -0.37441616  0.35465473  0.26122535  0.27722369\n",
      "  0.18127723 -0.21548902  0.43849536 -0.35000487  0.1626922   0.4848214\n",
      " -1.11940362  0.64138983  0.21778928 -0.20569954  0.30053177 -0.68255651\n",
      " -0.47785175  0.60637537  0.37396765 -0.57394712 -0.2051439  -0.25084181\n",
      "  0.44839197 -0.25616531  0.56920789  0.15104951  0.42512035  0.4532414\n",
      "  0.46418045 -0.76908909  0.15770926  0.06937659  0.16571777  0.2993753\n",
      " -0.09841439 -0.08060645 -0.0779761   0.28948209  0.25300015 -0.04764613\n",
      "  0.25596735]\n",
      "Final Training Accuracy: 0.9698795180722891\n",
      "Total iterations: 17\n",
      "Test accuracy: 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a function for predictions based on the NSSVM model output\n",
    "def predict_NSSVM(X, model_output):\n",
    "    w = model_output['w'][:-1]  # assuming last element in 'w' is the bias\n",
    "    b = model_output['w'][-1]\n",
    "    return np.sign(X.dot(w) + b)  # Apply the sign function to get binary predictions\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# The last column contains labels: 'R' for rock and 'M' for mine\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Convert class labels 'R' and 'M' to -1 and 1\n",
    "y = np.where(y == 'R', -1, 1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def run_NSSVM(X_train, y_train, X_test, y_test, pars):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train the model\n",
    "    model_output = NSSVM(X_train_scaled, y_train, pars)\n",
    "    print(\"Training complete.\")\n",
    "    print(\"Model weights:\", model_output['w'])\n",
    "    print(\"Final Training Accuracy:\", model_output['ACC'])\n",
    "    print(\"Total iterations:\", model_output['iter'])\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    predictions = predict_NSSVM(X_test_scaled, model_output)\n",
    "    test_accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "    return model_output\n",
    "\n",
    "# Define parameters\n",
    "pars = {\"maxit\": 2000, \"tol\": 1e-6, \"C\": 1.0, \"disp\": True}\n",
    "\n",
    "# Run with the updated parameters and data scaling\n",
    "model_output = run_NSSVM(X_train, y_train, X_test, y_test, pars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nkwNRsxGOdsF",
   "metadata": {
    "id": "nkwNRsxGOdsF"
   },
   "source": [
    "# heart disease dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "PqmfZO94qfF0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqmfZO94qfF0",
    "outputId": "af57dbeb-fcd2-49d2-895b-759170d24b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run NSSVM ......\n",
      "------------------------------------------\n",
      "  Iter          Error           Accuracy  \n",
      "------------------------------------------\n",
      "    1          7.43e-02         0.52321\n",
      "    2          3.35e+01         0.83544\n",
      "    3          4.94e+00         0.84388\n",
      "    4          3.89e-02         0.84388\n",
      "    5          7.23e-04         0.84388\n",
      "    6          8.88e-02         0.84388\n",
      "    7          6.59e-09         0.84388\n",
      "------------------------------------------\n",
      "Training complete.\n",
      "Model weights: [-0.03634618  0.217803    0.11810525  0.14576381  0.10908207 -0.15354085\n",
      "  0.0742419  -0.1689725   0.17420868  0.11531894  0.07345408  0.40082847\n",
      "  0.18542649 -0.04051312]\n",
      "Final Accuracy: 0.8438818565400844\n",
      "Total iterations: 7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Heart Disease dataset from UCI Repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'\n",
    "]\n",
    "data = pd.read_csv(url, names=column_names, na_values='?')\n",
    "\n",
    "# Handle missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convert the 'num' attribute to a binary classification target:\n",
    "# 0 means 'no presence' of heart disease, and 1-4 mean 'presence' of heart disease\n",
    "data['num'] = (data['num'] > 0).astype(int)\n",
    "\n",
    "# Convert class labels 0 to -1 for binary classification\n",
    "y = np.where(data['num'] == 0, -1, 1)\n",
    "\n",
    "# Extract features\n",
    "X = data.iloc[:, :-1].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def run_NSSVM(X_train, y_train, X_test, y_test, pars):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Assuming NSSVM function is defined and imports are handled\n",
    "    model_output = NSSVM(X_train_scaled, y_train, pars)\n",
    "    print(\"Training complete.\")\n",
    "    print(\"Model weights:\", model_output['w'])\n",
    "    print(\"Final Accuracy:\", model_output['ACC'])\n",
    "    print(\"Total iterations:\", model_output['iter'])\n",
    "\n",
    "    # Optionally evaluate on the test set\n",
    "    # predictions = predict_NSSVM(X_test_scaled, model_output['w'])\n",
    "    # test_accuracy = accuracy_score(y_test, predictions)\n",
    "    # print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "    return model_output\n",
    "\n",
    "# Define parameters\n",
    "pars = {\"maxit\": 2000, \"tol\": 1e-6, \"C\": 1.0, \"disp\": True}\n",
    "\n",
    "# Run with the updated parameters and data scaling\n",
    "model_output = run_NSSVM(X_train, y_train, X_test, y_test, pars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac2c78",
   "metadata": {
    "id": "nkN8R8gHqepR"
   },
   "source": [
    "# dhrb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60dedc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run NSSVM ......\n",
      "------------------------------------------\n",
      "  Iter          Error           Accuracy  \n",
      "------------------------------------------\n",
      "    1          1.38e-04         0.82848\n",
      "    2          4.29e-02         0.82430\n",
      "    3          1.31e-03         0.57471\n",
      "    4          7.42e-04         0.54331\n",
      "    5          1.91e-09         0.62695\n",
      "    6          7.94e-32         0.62678\n",
      "------------------------------------------\n",
      "Training complete.\n",
      "Model weights: [-0.2094981  -0.05200466  0.17280422  0.04028559  0.10612397  0.00363238\n",
      "  0.14507248 -0.1534323   0.09777412  0.03025629 -0.00809935  0.14009657\n",
      "  0.13829572 -0.0401651  -0.04209933  0.09400907  0.01587642 -0.99718262]\n",
      "Final Accuracy: 0.8243047539091195\n",
      "Total iterations: 6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "data_path = \"./data/dhrb.mat\"\n",
    "data2_path = \"./data/dhrbclass.mat\"\n",
    "data = scipy.io.loadmat(data_path)\n",
    "data2 = scipy.io.loadmat(data2_path)\n",
    "\n",
    "X = data['X']\n",
    "y = data2['y'].flatten()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def run_NSSVM(X_train, y_train, X_test, y_test, pars):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train the model\n",
    "    model_output = NSSVM(X_train_scaled, y_train, pars)\n",
    "    print(\"Training complete.\")\n",
    "    print(\"Model weights:\", model_output['w'])\n",
    "    print(\"Final Accuracy:\", model_output['ACC'])\n",
    "    print(\"Total iterations:\", model_output['iter'])\n",
    "\n",
    "    # If you need to evaluate on the test set, include this and ensure predict_NSSVM is implemented\n",
    "    # predictions = predict_NSSVM(X_test_scaled, model_output['w'])\n",
    "    # test_accuracy = accuracy_score(y_test, predictions)\n",
    "    # print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "    return model_output\n",
    "\n",
    "# Define parameters\n",
    "pars = {\"maxit\": 2000, \"lr\": 0.01, \"C\": 1.0, \"disp\": True}\n",
    "\n",
    "# Run with the updated parameters and data scaling\n",
    "model_output = run_NSSVM(X_train, y_train, X_test, y_test, pars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7c54b",
   "metadata": {},
   "source": [
    "## Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd9207d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run NSSVM ......\n",
      "------------------------------------------\n",
      "  Iter          Error           Accuracy  \n",
      "------------------------------------------\n",
      "    1          2.34e-01         0.52500\n",
      "    2          1.01e+02         1.00000\n",
      "------------------------------------------\n",
      "Training complete.\n",
      "Model weights: [-0.03072836 -0.17170956  0.49830904  0.39881557  0.05218903]\n",
      "Final Accuracy: 1.0\n",
      "Total iterations: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[iris.target != 2]  # Select only the first two classes for binary classification\n",
    "y = iris.target[iris.target != 2]\n",
    "y[y == 0] = -1  # Convert class labels to -1 and 1\n",
    "y[y == 1] = 1\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def run_NSSVM(X_train, y_train, X_test, y_test, pars):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train the model\n",
    "    model_output = NSSVM(X_train_scaled, y_train, pars)\n",
    "    print(\"Training complete.\")\n",
    "    print(\"Model weights:\", model_output['w'])\n",
    "    print(\"Final Accuracy:\", model_output['ACC'])\n",
    "    print(\"Total iterations:\", model_output['iter'])\n",
    "\n",
    "    # If you need to evaluate on the test set, here's a placeholder for prediction logic\n",
    "    # predictions = predict_NSSVM(X_test_scaled, model_output['w'])\n",
    "    # test_accuracy = accuracy_score(y_test, predictions)\n",
    "    # print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "    return model_output\n",
    "\n",
    "# Define parameters\n",
    "pars = {\"maxit\": 2000, \"tol\": 1e-6, \"C\": 1.0, \"disp\": True}\n",
    "\n",
    "# Run with the updated parameters and data scaling\n",
    "model_output = run_NSSVM(X_train, y_train, X_test, y_test, pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfe5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
