{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e315bb73",
      "metadata": {
        "id": "e315bb73"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import scipy.io\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_45tQB44A61-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7973a6-68d3-413e-9de6-d38306ac8d53"
      },
      "id": "_45tQB44A61-",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f3ace562",
      "metadata": {
        "id": "f3ace562"
      },
      "outputs": [],
      "source": [
        "# Load the data (assuming it's already loaded)\n",
        "data = scipy.io.loadmat(\"/content/drive/MyDrive/ml_data/dhrb.mat\")\n",
        "data2 = scipy.io.loadmat(\"/content/drive/MyDrive/ml_data/dhrbclass.mat\")\n",
        "\n",
        "X = data['X']\n",
        "y = data2['y'].flatten()  # Flatten the array to make it 1D\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d3e5bfc3",
      "metadata": {
        "id": "d3e5bfc3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import issparse\n",
        "from time import time\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.io\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "from scipy.sparse import diags, issparse\n",
        "def NSSVM(X, y, pars=None):\n",
        "    import numpy as np\n",
        "    import scipy.sparse as sp\n",
        "\n",
        "    def Fnorm(var):\n",
        "        return np.linalg.norm(var)**2\n",
        "\n",
        "    def GetParameters(m, n):\n",
        "        maxit = 1e3\n",
        "        alpha = np.zeros(m)\n",
        "        tune = 0\n",
        "        disp = 1\n",
        "        tol = 1e-6\n",
        "        eta = min(1/m, 1e-4)\n",
        "        if max(m, n) < 1e4:\n",
        "            beta = 1\n",
        "        elif m <= 5e5:\n",
        "            beta = 0.05\n",
        "        elif m <= 1e8:\n",
        "            beta = 10\n",
        "        s0 = np.ceil(beta * n * (np.log2(m/n))**2)\n",
        "        if m > 5e6:\n",
        "            C = np.log10(m)\n",
        "        else:\n",
        "            C = 1/2\n",
        "        c = C/100\n",
        "        return maxit, alpha, tune, disp, tol, eta, s0, C, c\n",
        "\n",
        "    def my_cg(Q, y, E, b, cgtol, cgit, x):\n",
        "        r = b\n",
        "        e = np.sum(r*r)\n",
        "        t = e\n",
        "        for i in range(cgit):\n",
        "            if e < cgtol*t:\n",
        "                break\n",
        "            if i == 0:\n",
        "                p = r\n",
        "            else:\n",
        "                p = r + (e/e0)*p\n",
        "            p1 = p[:-1]\n",
        "            w = np.concatenate((((Q.dot(p1)).dot(Q.T)).T + E*p1 + p[-1]*y, np.sum(y*p1)))\n",
        "            a = e/np.sum(p*w)\n",
        "            x = x + a*p\n",
        "            r = r - a*w\n",
        "            e0 = e\n",
        "            e = np.sum(r*r)\n",
        "        return x\n",
        "\n",
        "    if pars is None:\n",
        "        pars = {}\n",
        "\n",
        "    t0 = 0\n",
        "    m, n = X.shape\n",
        "\n",
        "    if sp.issparse(X) and sp.issparse(X) and sp.issparse(X)/m/n > 0.1:\n",
        "        X = X.toarray()\n",
        "\n",
        "    # if n < 3e4:\n",
        "    #     Qt = y*X\n",
        "    # else:\n",
        "    #     Qt = sp.diags(y, 0, m, m)*X\n",
        "\n",
        "    if y.ndim != 1 or y.shape[0] != m:\n",
        "        raise ValueError(\"y must be a 1D array with the same number of elements as rows in X\")\n",
        "\n",
        "    if n < 3e4:\n",
        "        Qt = y[:, np.newaxis] * X\n",
        "    else:\n",
        "        if y.shape[0] != X.shape[0]:  # Ensuring y and X have matching dimensions\n",
        "            raise ValueError(\"Mismatched dimensions between y and X: {} vs {}\".format(y.shape[0], X.shape[0]))\n",
        "        Qt = sp.diags(y, 0, shape=(m, m)) * X\n",
        "\n",
        "\n",
        "    Q = Qt.T\n",
        "    maxit, alpha, tune, disp, tol, eta, s0, C, c = GetParameters(m, n)\n",
        "\n",
        "    if 'maxit' in pars:\n",
        "        maxit = pars['maxit']\n",
        "    if 'alpha' in pars:\n",
        "        alpha = pars['alpha']\n",
        "    if 'disp' in pars:\n",
        "        disp = pars['disp']\n",
        "    if 'tune' in pars:\n",
        "        tune = pars['tune']\n",
        "    if 'tol' in pars:\n",
        "        tol = pars['tol']\n",
        "    if 'eta' in pars:\n",
        "        eta = pars['eta']\n",
        "    if 's0' in pars:\n",
        "        s0 = min(m, int(pars['s0']))\n",
        "    if 'C' in pars:\n",
        "        C = pars['C']\n",
        "    if 'c' in pars:\n",
        "        c = pars['c']\n",
        "\n",
        "    T1 = np.where(y == 1)[0]\n",
        "    nT1 = len(T1)\n",
        "    T2 = np.where(y == -1)[0]\n",
        "    nT2 = len(T2)\n",
        "\n",
        "    if nT1 < s0:\n",
        "        T = np.concatenate((T1, T2[:int(s0 - nT1)]))  # Cast to int\n",
        "    elif nT2 < s0:\n",
        "        T = np.concatenate((T1[:int(s0 - nT2)], T2))  # Cast to int\n",
        "    else:\n",
        "        T = np.concatenate((T1[:int(np.ceil(s0 / 2))], T2[:int(s0 - np.ceil(s0 / 2))]))  # Ensure all indices are integers\n",
        "    T = np.sort(T[:int(s0)])\n",
        "    s = int(s0)\n",
        "    b = (nT1 >= nT2) - (nT1 < nT2)\n",
        "    bb = b\n",
        "    w = np.zeros(n)\n",
        "    gz = -np.ones(m)\n",
        "    ERR = np.zeros(maxit)\n",
        "    ACC = np.zeros(maxit)\n",
        "    ACC[0] = 1 - np.count_nonzero(np.sign(b)-y)/m\n",
        "    ET = np.ones(s)/C\n",
        "\n",
        "    maxACC = 0\n",
        "    flag = 1\n",
        "    j = 1\n",
        "    r = 1.1\n",
        "    count = 1\n",
        "    count0 = 2\n",
        "    iter0 = -1\n",
        "\n",
        "    if disp:\n",
        "        print('Run NSSVM ......')\n",
        "        print('------------------------------------------')\n",
        "        print('  Iter          Error           Accuracy  ')\n",
        "        print('------------------------------------------')\n",
        "\n",
        "    for iter in range(1, maxit+1):\n",
        "        if iter == 1 or flag:\n",
        "            QT = Q[:, T]\n",
        "            QtT = Qt[T, :]\n",
        "            yT = y[T]\n",
        "            ytT = yT.T\n",
        "\n",
        "        alphaT = alpha[T]\n",
        "        gzT = -gz[T]\n",
        "        alyT = -ytT.dot(alphaT)\n",
        "\n",
        "        err = (np.abs(Fnorm(alpha)-Fnorm(alphaT)) + Fnorm(gzT) + alyT**2)/(m*n)\n",
        "        ERR[iter-1] = np.sqrt(err)\n",
        "\n",
        "        if tune and iter < 30 and m <= 1e8:\n",
        "            stop1 = (iter > 5 and err < tol*s*np.log2(m)/100)\n",
        "            stop2 = (s != s0 and np.abs(ACC[iter-1] - np.max(ACC[:iter-1])) <= 1e-4)\n",
        "            stop3 = (s != s0 and iter > 10 and np.max(ACC[iter-5:iter]) < maxACC)\n",
        "            stop4 = (count != count0+1 and ACC[iter] >= ACC[0])\n",
        "            stop = (stop1 and (stop2 or stop3) and stop4)\n",
        "        else:\n",
        "            stop1 = (err < tol*np.sqrt(s)*np.log10(m))\n",
        "            stop2 = (iter > 4 and np.std(ACC[iter-2:iter]) < 1e-4)\n",
        "            stop3 = (iter > 20 and np.abs(np.max(ACC[iter-8:iter]) - maxACC) <= 1e-4)\n",
        "            stop = (stop1 and stop2) or stop3\n",
        "\n",
        "        if disp:\n",
        "            print(f'  {iter:3d}          {err:6.2e}         {ACC[iter-1]:7.5f}')\n",
        "\n",
        "        if ACC[iter-1] > 0 and (ACC[iter-1] >= 0.99999 or stop):\n",
        "            break\n",
        "\n",
        "        ET0 = ET\n",
        "        ET = (alphaT >= 0)/C + (alphaT < 0)/c\n",
        "\n",
        "        if min(n, s) > 1e3:\n",
        "            d = my_cg(QT, yT, ET, np.concatenate((gzT, alyT)), 1e-10, 50, np.zeros(s+1))\n",
        "            dT = d[:s]\n",
        "            dend = d[-1]\n",
        "        else:\n",
        "            if s <= n:\n",
        "                if iter == 1 or flag:\n",
        "                    PTT0 = QtT.dot(QT)\n",
        "                PTT = PTT0 + sp.diags(ET, 0, (s, s))\n",
        "                d = np.linalg.solve(np.concatenate((np.concatenate((PTT, yT[:, np.newaxis]), axis=1), np.concatenate((ytT[:, np.newaxis], np.zeros((1, 1))), axis=1))), np.concatenate((gzT, alyT)))\n",
        "                dT = d[:s]\n",
        "                dend = d[-1]\n",
        "            else:\n",
        "                ETinv = 1/ET\n",
        "                flag1 = np.count_nonzero(ET0) != np.count_nonzero(ET)\n",
        "                flag2 = np.count_nonzero(ET0) == np.count_nonzero(ET) and np.count_nonzero(ET0-ET) == 0\n",
        "                if iter == 1 or flag or flag1 or not flag2:\n",
        "                    EQtT = sp.diags(ETinv, 0, (s, s)).dot(QtT)\n",
        "                    P0 = np.eye(n) + QT.dot(EQtT)\n",
        "                Ey = ETinv*yT\n",
        "                Hy = Ey - EQtT.dot(np.linalg.solve(P0, QT.dot(Ey)))\n",
        "                dend = (gzT.dot(Hy) - alyT)/(ytT.dot(Hy))\n",
        "                tem = ETinv*(gzT - dend*yT)\n",
        "                dT = tem - EQtT.dot(np.linalg.solve(P0, QT.dot(tem)))\n",
        "\n",
        "        alpha = np.zeros(m)\n",
        "        alphaT = alphaT + dT\n",
        "        alpha[T] = alphaT\n",
        "        b = b + dend\n",
        "\n",
        "        w = QT.dot(alphaT)\n",
        "        Qtw = Qt.dot(w)\n",
        "        tmp = y*Qtw\n",
        "\n",
        "        gz = Qtw - 1 + b*y\n",
        "        ET1 = (alphaT >= 0)/C + (alphaT < 0)/c\n",
        "        gz[T] = alphaT*ET1 + gz[T]\n",
        "\n",
        "        j = iter+1\n",
        "        ACC[j-1] = 1 - np.count_nonzero(np.sign(tmp+b)-y)/m\n",
        "\n",
        "        if m <= 1e7:\n",
        "            bb = np.mean(yT - tmp[T])\n",
        "            ACCb = 1 - np.count_nonzero(np.sign(tmp+bb)-y)/m\n",
        "            if ACC[j-1] >= ACCb:\n",
        "                bb = b\n",
        "            else:\n",
        "                ACC[j-1] = ACCb\n",
        "        else:\n",
        "            bb = b\n",
        "\n",
        "        if m < 6e6 and ACC[j-1] < 0.5:\n",
        "            opt = {'maxiter': 10*(m >= 1e6) + 20*(m < 1e6), 'disp': False}\n",
        "            b0 = minimize(lambda t: np.sum((np.sign(tmp+t[0])-y)**2), bb, options=opt).x[0]\n",
        "            acc0 = 1 - np.count_nonzero(np.sign(tmp+b0)-y)/m\n",
        "            if ACC[j-1] < acc0:\n",
        "                bb = b0\n",
        "                ACC[j-1] = acc0\n",
        "\n",
        "        if ACC[j-1] >= maxACC:\n",
        "            maxACC = ACC[j-1]\n",
        "            alpha0 = alpha.copy()\n",
        "            tmp0 = tmp.copy()\n",
        "            maxwb = np.concatenate((w, [bb]))\n",
        "\n",
        "        T0 = T.copy()\n",
        "        mark = 0\n",
        "        if tune and (err < tol or iter % 10 == 0) and iter > iter0+2 and count < 10:\n",
        "            count0 = count\n",
        "            count = count + 1\n",
        "            s = min(m, np.ceil(r*s))\n",
        "            iter0 = iter\n",
        "            if count > (m >= 1e6 or n < 3) + 1*(m < 1e6 and n >= 5):\n",
        "                alpha = np.zeros(m)\n",
        "                gz = -np.ones(m)\n",
        "                mark = 1\n",
        "        else:\n",
        "            count0 = count\n",
        "\n",
        "        if s != m:\n",
        "            if m < 5e8:\n",
        "              T = np.argsort(np.abs(alpha - eta * gz))[-s:]\n",
        "            else:\n",
        "              T = np.argsort(np.abs(alpha - eta * gz))[::-1][:s]\n",
        "            T = np.sort(T[:s])\n",
        "            if mark:\n",
        "                nT = np.count_nonzero(y[T] == 1)\n",
        "                if nT == s:\n",
        "                    if nT2 <= 0.75*s:\n",
        "                        T = np.concatenate((T[:s-np.ceil(nT2/2)], T2[:np.ceil(nT2/2)]))\n",
        "                    else:\n",
        "                        T = np.concatenate((T[:np.ceil(s/4)], T2[:s-np.ceil(s/4)]))\n",
        "                elif nT == 0:\n",
        "                    if nT1 <= 0.75*s:\n",
        "                        T = np.concatenate((T[:s-np.ceil(nT1/2)], T1[:np.ceil(nT1/2)]))\n",
        "                    else:\n",
        "                        T = np.concatenate((T[:np.ceil(s/4)], T1[:s-np.ceil(s/4)]))\n",
        "                T = np.sort(T[:s])\n",
        "        else:\n",
        "            T = np.arange(m)\n",
        "\n",
        "        flag = 1\n",
        "        flag3 = np.count_nonzero(T0) == s\n",
        "\n",
        "        if flag3:\n",
        "            flag3 = np.count_nonzero(T-T0) == 0\n",
        "\n",
        "        if flag3 or np.count_nonzero(T0) == m:\n",
        "            flag = 0\n",
        "            T = T0\n",
        "\n",
        "    wb = np.concatenate((w, [bb]))\n",
        "    acc = ACC[j-1]\n",
        "\n",
        "    if m <= 1e7 and iter > 1:\n",
        "        opt = {'maxiter': 20, 'disp': False}\n",
        "        b0 = minimize(lambda t: np.linalg.norm(np.sign(tmp0+t[0])-y), maxwb[-1], options=opt).x[0]\n",
        "        acc0 = 1 - np.count_nonzero(np.sign(tmp0+b0)-y)/m\n",
        "        if acc < acc0:\n",
        "            wb = np.concatenate((maxwb[:-1], [b0]))\n",
        "            acc = acc0\n",
        "\n",
        "    if acc < maxACC-1e-4:\n",
        "        alpha = alpha0.copy()\n",
        "        wb = maxwb.copy()\n",
        "        acc = maxACC\n",
        "\n",
        "    if disp:\n",
        "        print('------------------------------------------')\n",
        "\n",
        "    Out = {'s': s, 'w': wb, 'sv': s, 'ACC': acc, 'iter': iter, 'time': 0-t0, 'alpha': alpha}\n",
        "    return Out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load your data\n",
        "data_path = \"/content/drive/MyDrive/ml_data/dhrb.mat\"\n",
        "data2_path = \"/content/drive/MyDrive/ml_data/dhrbclass.mat\"\n",
        "data = scipy.io.loadmat(data_path)\n",
        "data2 = scipy.io.loadmat(data2_path)\n",
        "\n",
        "X = data['X']\n",
        "y = data2['y'].flatten()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def run_NSSVM(X_train, y_train, X_test, y_test, pars):\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Train the model\n",
        "    model_output = NSSVM(X_train_scaled, y_train, pars)\n",
        "    print(\"Training complete.\")\n",
        "    print(\"Model weights:\", model_output['w'])\n",
        "    print(\"Final Accuracy:\", model_output['ACC'])\n",
        "    print(\"Total iterations:\", model_output['iter'])\n",
        "    print(\"Training time:\", model_output['time'], \"seconds\")\n",
        "\n",
        "    # If you need to evaluate on the test set, include this and ensure predict_NSSVM is implemented\n",
        "    # predictions = predict_NSSVM(X_test_scaled, model_output['w'])\n",
        "    # test_accuracy = accuracy_score(y_test, predictions)\n",
        "    # print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "    return model_output\n",
        "\n",
        "# Define parameters\n",
        "pars = {\"maxit\": 2000, \"lr\": 0.01, \"C\": 1.0, \"disp\": True}\n",
        "\n",
        "# Run with the updated parameters and data scaling\n",
        "model_output = run_NSSVM(X_train, y_train, X_test, y_test, pars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siRZ0UxngV_L",
        "outputId": "d4db5592-d0d6-464f-f23e-79a421f6906f"
      },
      "id": "siRZ0UxngV_L",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NSSVM ......\n",
            "------------------------------------------\n",
            "  Iter          Error           Accuracy  \n",
            "------------------------------------------\n",
            "    1          1.38e-04         0.82848\n",
            "    2          4.29e-02         0.82430\n",
            "    3          1.31e-03         0.57471\n",
            "    4          7.42e-04         0.54331\n",
            "    5          1.91e-09         0.62695\n",
            "    6          5.39e-32         0.62678\n",
            "------------------------------------------\n",
            "Training complete.\n",
            "Model weights: [-0.2094981  -0.05200466  0.17280422  0.04028559  0.10612397  0.00363238\n",
            "  0.14507248 -0.1534323   0.09777412  0.03025629 -0.00809935  0.14009657\n",
            "  0.13829572 -0.0401651  -0.04209933  0.09400907  0.01587642 -0.99718262]\n",
            "Final Accuracy: 0.8243047539091195\n",
            "Total iterations: 6\n",
            "Training time: 0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## iris dataset"
      ],
      "metadata": {
        "id": "rRbOYRc-lgN3"
      },
      "id": "rRbOYRc-lgN3"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[iris.target != 2]  # Select only the first two classes for binary classification\n",
        "y = iris.target[iris.target != 2]\n",
        "y[y == 0] = -1  # Convert class labels to -1 and 1\n",
        "y[y == 1] = 1\n",
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def run_NSSVM(X_train, y_train, X_test, y_test, pars):\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Train the model\n",
        "    model_output = NSSVM(X_train_scaled, y_train, pars)\n",
        "    print(\"Training complete.\")\n",
        "    print(\"Model weights:\", model_output['w'])\n",
        "    print(\"Final Accuracy:\", model_output['ACC'])\n",
        "    print(\"Total iterations:\", model_output['iter'])\n",
        "    print(\"Training time:\", model_output['time'], \"seconds\")\n",
        "\n",
        "    # If you need to evaluate on the test set, here's a placeholder for prediction logic\n",
        "    # predictions = predict_NSSVM(X_test_scaled, model_output['w'])\n",
        "    # test_accuracy = accuracy_score(y_test, predictions)\n",
        "    # print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "    return model_output\n",
        "\n",
        "# Define parameters\n",
        "pars = {\"maxit\": 2000, \"tol\": 1e-6, \"C\": 1.0, \"disp\": True}\n",
        "\n",
        "# Run with the updated parameters and data scaling\n",
        "model_output = run_NSSVM(X_train, y_train, X_test, y_test, pars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HRck8OcxB7K",
        "outputId": "2c006032-eab8-4c2a-888a-628baa7d0610"
      },
      "id": "0HRck8OcxB7K",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NSSVM ......\n",
            "------------------------------------------\n",
            "  Iter          Error           Accuracy  \n",
            "------------------------------------------\n",
            "    1          2.34e-01         0.52500\n",
            "    2          1.01e+02         1.00000\n",
            "------------------------------------------\n",
            "Training complete.\n",
            "Model weights: [-0.03072836 -0.17170956  0.49830904  0.39881557  0.05218903]\n",
            "Final Accuracy: 1.0\n",
            "Total iterations: 2\n",
            "Training time: 0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a5a.t dataset"
      ],
      "metadata": {
        "id": "SmsEK-fOshr2"
      },
      "id": "SmsEK-fOshr2"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "# Load the dataset from the LIBSVM format file\n",
        "X, y = load_svmlight_file('/content/drive/MyDrive/ml_data/a5a.t')\n",
        "\n",
        "# Convert to dense format as many scikit-learn estimators expect dense format\n",
        "X_dense = X.toarray()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def predict_NSSVM(X, model_output):\n",
        "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
        "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
        "    b = model_output['w'][-1]\n",
        "    return np.sign(X.dot(w) + b)\n",
        "\n",
        "# Timing the NSSVM training\n",
        "start_time = time.time()\n",
        "\n",
        "# Run NSSVM on the training data\n",
        "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
        "\n",
        "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
        "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
        "\n",
        "# Calculate and print accuracies\n",
        "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
        "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(\"Model weights:\", model_output['w'])\n",
        "print(\"Final Training Accuracy:\", train_accuracy)\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "print(\"Total iterations:\", model_output['iter'])\n",
        "print(\"Training time:\", elapsed_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d05SMWu0eoT",
        "outputId": "ca1199c6-9df7-44f7-c7e9-81dceeda8652"
      },
      "id": "4d05SMWu0eoT",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NSSVM ......\n",
            "------------------------------------------\n",
            "  Iter          Error           Accuracy  \n",
            "------------------------------------------\n",
            "    1          1.31e-04         0.75895\n",
            "    2          9.71e-02         0.79204\n",
            "    3          2.70e-02         0.75245\n",
            "    4          4.42e-03         0.75580\n",
            "    5          1.16e-02         0.76761\n",
            "    6          1.07e-02         0.75341\n",
            "    7          2.41e-02         0.75929\n",
            "    8          9.56e-03         0.74619\n",
            "    9          2.94e-03         0.71975\n",
            "   10          4.07e-03         0.75097\n",
            "   11          8.92e-05         0.74365\n",
            "   12          1.64e-04         0.75259\n",
            "   13          3.05e-06         0.75355\n",
            "   14          2.43e-06         0.75503\n",
            "   15          2.57e-06         0.75632\n",
            "   16          7.70e-06         0.75298\n",
            "   17          6.69e-06         0.75427\n",
            "   18          1.77e-06         0.75537\n",
            "   19          3.60e-09         0.76067\n",
            "   20          1.42e-30         0.76024\n",
            "   21          6.73e-31         0.76024\n",
            "------------------------------------------\n",
            "Training complete.\n",
            "Model weights: [ 6.36136778e-03 -4.44883886e-02 -2.02690596e-02  6.88049643e-04\n",
            "  5.45675708e-02  6.23470104e-02  1.79632825e-02  9.21461284e-02\n",
            "  3.01104484e-02  5.03441589e-03 -5.89195075e-02 -1.68962067e-15\n",
            " -9.71445147e-16  7.41216608e-03  4.42175100e-02 -5.83665906e-02\n",
            "  1.20884888e-02 -5.35933396e-03 -1.04598086e-02  2.33457087e-02\n",
            " -3.67286409e-02 -7.65909008e-03  7.41774086e-02  2.31772924e-02\n",
            " -5.00207067e-03 -7.52176099e-15 -5.49167261e-02 -6.13556856e-02\n",
            "  1.78161961e-02 -5.21605369e-02 -3.27155398e-02  6.77196584e-02\n",
            "  4.16340111e-02 -2.06085149e-15 -7.90704963e-02 -7.65909008e-03\n",
            "  2.33457087e-02  1.17237050e-02  4.01095278e-02  1.54387746e-01\n",
            "  1.90118443e-02 -1.46588210e-01 -6.83042081e-02 -2.17392876e-02\n",
            "  7.61770137e-03 -1.15185639e-15  5.74100442e-02 -5.19760923e-02\n",
            " -7.70271995e-02  9.10424509e-02  8.96198391e-02  1.37394709e-01\n",
            " -3.68833742e-02 -5.87229656e-03  5.49656891e-03 -4.35424948e-02\n",
            " -9.34088937e-02 -6.30051566e-15  5.40246936e-02 -1.41553436e-15\n",
            "  7.94156797e-02 -4.01510385e-02  5.45475240e-02 -7.20495047e-03\n",
            " -1.60780554e-02 -7.61194440e-02 -3.04982444e-03  3.40712921e-02\n",
            " -2.82803960e-02 -2.91973309e-02  1.44170035e-03 -4.20095882e-02\n",
            "  4.20095882e-02 -5.50350699e-02  5.50350699e-02 -3.81632170e-02\n",
            "  3.81632170e-02 -6.09016848e-02  5.20160715e-03 -2.39960775e-02\n",
            "  2.24726811e-02  6.75178078e-02 -2.80161483e-01 -1.89431804e-15\n",
            " -1.32402279e-02 -5.18533739e-02 -3.59736767e-02 -7.07904649e-02\n",
            " -1.26634814e-15 -3.40005801e-15 -6.07876386e-02 -2.11636264e-15\n",
            " -9.88596611e-02 -7.39504282e-02 -1.09687975e-01 -2.52575738e-15\n",
            " -1.06512021e-15 -1.11927007e-01 -5.02007034e-02 -2.24126273e-15\n",
            " -3.93435284e-15 -5.06691251e-02 -1.84769269e-01 -2.44249065e-15\n",
            " -1.30104261e-15 -1.86656246e-15 -3.19189120e-15 -2.15799600e-15\n",
            " -2.06779038e-15 -2.15799600e-15 -2.64411262e-02 -3.84102671e-02\n",
            " -1.25593980e-15 -3.07393000e-15 -1.79023463e-15 -1.59594560e-15\n",
            " -1.47798440e-15 -1.59594560e-15 -4.18415302e-15 -1.94635974e-15\n",
            " -2.35228503e-15 -1.67227343e-15 -4.64786302e-16 -1.18213031e+00]\n",
            "Final Training Accuracy: 79.2035186690252\n",
            "Testing Accuracy: 79.33078393881453\n",
            "Total iterations: 21\n",
            "Training time: 0.11704397201538086 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# a6a dataset"
      ],
      "metadata": {
        "id": "HsJm4mVdO-2X"
      },
      "id": "HsJm4mVdO-2X"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "# Load the dataset from the LIBSVM format file\n",
        "X, y = load_svmlight_file('/content/drive/MyDrive/ml_data/a6a.t')\n",
        "\n",
        "# Convert to dense format as many scikit-learn estimators expect dense format\n",
        "X_dense = X.toarray()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def predict_NSSVM(X, model_output):\n",
        "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
        "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
        "    b = model_output['w'][-1]\n",
        "    return np.sign(X.dot(w) + b)\n",
        "\n",
        "# Timing the NSSVM training\n",
        "start_time = time.time()\n",
        "\n",
        "# Run NSSVM on the training data\n",
        "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
        "\n",
        "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
        "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
        "\n",
        "# Calculate and print accuracies\n",
        "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
        "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(\"Model weights:\", model_output['w'])\n",
        "print(\"Final Training Accuracy:\", train_accuracy)\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "print(\"Total iterations:\", model_output['iter'])\n",
        "print(\"Training time:\", elapsed_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbDzVK6sOjhd",
        "outputId": "feb0d29c-c0f3-4fad-83a5-100b6f0110bd"
      },
      "id": "dbDzVK6sOjhd",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NSSVM ......\n",
            "------------------------------------------\n",
            "  Iter          Error           Accuracy  \n",
            "------------------------------------------\n",
            "    1          1.49e-04         0.75756\n",
            "    2          9.29e-02         0.78368\n",
            "    3          3.48e-02         0.77595\n",
            "    4          1.15e-02         0.77571\n",
            "    5          2.41e-02         0.78187\n",
            "    6          2.91e-03         0.77894\n",
            "    7          3.34e-02         0.76933\n",
            "    8          2.57e-02         0.76025\n",
            "    9          3.13e-03         0.76992\n",
            "   10          7.63e-04         0.77929\n",
            "   11          2.09e-04         0.77864\n",
            "   12          4.53e-03         0.78022\n",
            "   13          2.06e-05         0.76863\n",
            "   14          5.20e-05         0.75996\n",
            "   15          1.32e-02         0.76593\n",
            "   16          1.05e-04         0.75638\n",
            "   17          8.69e-05         0.75574\n",
            "   18          7.73e-10         0.75539\n",
            "   19          5.18e-30         0.75545\n",
            "------------------------------------------\n",
            "Training complete.\n",
            "Model weights: [-5.57898627e-02 -7.23880726e-02  3.97736475e-02  9.91778925e-03\n",
            "  7.23976900e-02  1.64417032e-01  1.20674478e-01  3.80704455e-02\n",
            "  1.57865476e-01 -6.31784791e-03  1.02028184e-01  2.63677968e-16\n",
            "  7.84095011e-16  1.48543922e-02 -2.06740246e-02  8.61561461e-03\n",
            " -1.03304042e-02  7.51490997e-03  1.05978496e-01  7.12835963e-03\n",
            " -4.71294646e-02 -5.38099770e-02  4.14621618e-02 -3.63300163e-02\n",
            "  2.76757682e-02 -1.66097224e-02 -3.70636943e-02 -1.64337752e-02\n",
            "  2.69534247e-02  1.08246745e-15 -5.69297425e-02  2.70054461e-02\n",
            " -3.21257533e-02  7.35522754e-16 -9.11120665e-02 -5.38099770e-02\n",
            "  7.12835963e-03 -3.04603081e-03  1.24654756e-01  2.27882966e-01\n",
            " -1.87749984e-01 -4.69605984e-02 -8.70171475e-02 -1.40911631e-02\n",
            " -8.92493449e-02  1.76036642e-02  9.37111339e-02  6.75365144e-02\n",
            "  2.04748019e-02 -9.57426460e-03  9.94304179e-02  6.40223541e-02\n",
            "  2.09941648e-02  6.04096309e-02  1.04923820e-01 -6.40152988e-02\n",
            "  2.33164237e-03  1.61718922e-02  1.51453364e-01  4.23272528e-16\n",
            "  8.69605794e-02 -1.20961678e-01  2.17402341e-02  2.09943808e-02\n",
            " -2.49812879e-02  2.98973699e-02 -4.02332335e-02  5.22244965e-02\n",
            "  4.00121878e-04 -1.01546200e-01  4.96165970e-02 -3.04692725e-02\n",
            "  3.04692725e-02 -7.54318763e-02  7.54318763e-02  1.70831416e-02\n",
            " -1.70831416e-02 -2.64275453e-03  8.21674607e-03 -9.71834924e-03\n",
            "  5.59691953e-03  5.53003046e-03 -1.03637074e-01  1.11022302e-16\n",
            " -6.94454302e-02 -3.17256801e-02  2.16171874e-02 -3.23044443e-02\n",
            " -1.95828644e-02 -3.25937645e-02 -5.98285261e-02  8.88178420e-16\n",
            "  2.08166817e-15 -1.16323930e-01  1.13797860e-15  1.58206781e-15\n",
            "  9.02056208e-17 -6.80324494e-02 -2.77555756e-16  1.88737914e-15\n",
            " -1.69582009e-02  8.60422844e-16 -1.29483278e-01  5.82867088e-16\n",
            "  1.01307851e-15  3.88578059e-16  8.32667268e-17  6.80011603e-16\n",
            " -1.38777878e-17  7.63278329e-16  1.16573418e-15  9.29811783e-16\n",
            "  1.49206867e-02 -8.00452342e-03  6.93889390e-16  2.84494650e-16\n",
            "  4.71844785e-16  3.74700271e-16  1.22124533e-15  2.19422615e-03\n",
            "  6.97302863e-03  2.77555756e-16  6.57073785e-16 -1.31014713e+00]\n",
            "Final Training Accuracy: 78.36808809746955\n",
            "Testing Accuracy: 78.77723120168658\n",
            "Total iterations: 19\n",
            "Training time: 0.09686803817749023 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# a7a dataset"
      ],
      "metadata": {
        "id": "BxMjnVzPO5ut"
      },
      "id": "BxMjnVzPO5ut"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "# Load the dataset from the LIBSVM format file\n",
        "X, y = load_svmlight_file('/content/drive/MyDrive/ml_data/a7a.t')\n",
        "\n",
        "# Convert to dense format as many scikit-learn estimators expect dense format\n",
        "X_dense = X.toarray()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def predict_NSSVM(X, model_output):\n",
        "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
        "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
        "    b = model_output['w'][-1]\n",
        "    return np.sign(X.dot(w) + b)\n",
        "\n",
        "# Timing the NSSVM training\n",
        "start_time = time.time()\n",
        "\n",
        "# Run NSSVM on the training data\n",
        "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
        "\n",
        "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
        "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
        "\n",
        "# Calculate and print accuracies\n",
        "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
        "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(\"Model weights:\", model_output['w'])\n",
        "print(\"Final Training Accuracy:\", train_accuracy)\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "print(\"Total iterations:\", model_output['iter'])\n",
        "print(\"Training time:\", elapsed_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZWCOu7COjb7",
        "outputId": "3f9136df-dc82-4790-c6ff-29c4490ed10e"
      },
      "id": "QZWCOu7COjb7",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NSSVM ......\n",
            "------------------------------------------\n",
            "  Iter          Error           Accuracy  \n",
            "------------------------------------------\n",
            "    1          1.73e-04         0.76420\n",
            "    2          1.52e-01         0.79465\n",
            "    3          3.48e-02         0.77172\n",
            "    4          6.98e-03         0.76830\n",
            "    5          1.68e-02         0.77734\n",
            "    6          5.76e-03         0.76974\n",
            "    7          1.31e-02         0.77529\n",
            "    8          1.73e-03         0.78083\n",
            "    9          3.88e-04         0.78698\n",
            "   10          4.28e-05         0.78600\n",
            "   11          4.23e-04         0.77278\n",
            "   12          3.04e-06         0.77491\n",
            "   13          2.87e-06         0.77635\n",
            "   14          8.19e-06         0.77248\n",
            "   15          2.79e-06         0.77339\n",
            "   16          5.01e-06         0.77628\n",
            "   17          5.09e-09         0.77423\n",
            "   18          1.75e-20         0.77392\n",
            "   19          3.33e-31         0.77392\n",
            "------------------------------------------\n",
            "Training complete.\n",
            "Model weights: [-4.84215209e-02 -3.44054106e-02 -7.38284447e-03  9.57266447e-03\n",
            "  7.65779809e-02  1.62790149e-01  1.04294745e-01  9.34726329e-02\n",
            "  3.67889077e-03  5.04161290e-02  2.35697020e-02 -5.41233725e-16\n",
            " -5.34294831e-16  1.05243946e-02 -3.68645121e-02 -3.70966650e-02\n",
            "  2.96543202e-02  3.37955770e-02  2.04166004e-02  6.32416478e-03\n",
            "  3.40511101e-02 -5.94594511e-02  6.01568582e-02 -4.39584599e-02\n",
            "  7.01519588e-02 -6.19834667e-02  8.87208676e-02 -1.27353642e-02\n",
            "  6.59687679e-02 -2.02615702e-15 -1.01827636e-01 -3.88835825e-02\n",
            " -5.17720826e-03 -6.38378239e-16 -2.29090083e-02 -5.94594511e-02\n",
            "  6.32416478e-03  2.48121660e-02  6.09840035e-02 -2.11589388e-02\n",
            "  4.40379708e-03 -2.68347845e-02  2.01288260e-02  1.01428285e-01\n",
            " -2.27595720e-15  2.41672512e-02  3.66778619e-03  6.06754511e-02\n",
            "  2.38569382e-02  5.44048436e-02  1.16353855e-01  1.58201070e-01\n",
            " -3.13260013e-02 -1.02088103e-01  1.06030218e-01 -6.91843506e-02\n",
            " -4.18374065e-03 -1.19348975e-15  7.85971250e-02 -5.75928194e-16\n",
            "  8.40458927e-02 -1.45095601e-01  2.72749538e-01 -5.65522106e-02\n",
            " -1.13871639e-01 -1.78004029e-01 -1.56397996e-02  9.83340840e-02\n",
            " -5.27007463e-02 -1.63857933e-02 -1.64342972e-02 -1.03650469e-02\n",
            "  1.03650469e-02 -4.02635067e-02  4.02635067e-02 -3.80734724e-02\n",
            "  3.80734724e-02 -1.18549982e-01  4.61537773e-03  5.83153560e-03\n",
            "  6.34072358e-02  5.70237666e-02  1.46788383e-01 -5.89805982e-16\n",
            " -7.14977056e-02 -1.41553436e-15 -2.33146835e-15  5.34621964e-02\n",
            " -4.71844785e-16 -1.05863746e-02  2.20866744e-02 -5.34294831e-16\n",
            " -1.23512311e-15  3.99834742e-02 -7.15761311e-02  5.71147204e-02\n",
            " -8.32667268e-17  1.55102035e-02 -1.06858966e-15 -5.27355937e-16\n",
            " -8.31963558e-04 -1.06858966e-15 -6.08092717e-02  1.33250313e-02\n",
            " -6.59194921e-16 -2.28983499e-16 -1.19348975e-15 -8.18789481e-16\n",
            " -6.86950496e-16  1.88512787e-02  3.32163545e-02 -8.46545056e-16\n",
            " -4.40619763e-16 -8.04911693e-16 -9.26613433e-03 -3.95516953e-16\n",
            " -3.46944695e-16 -4.78783679e-16 -1.84574578e-15 -6.31439345e-16\n",
            " -6.52256027e-16 -7.56339436e-16 -2.53961186e-16 -1.29305064e+00]\n",
            "Final Training Accuracy: 79.46537059538275\n",
            "Testing Accuracy: 78.25690859398725\n",
            "Total iterations: 19\n",
            "Training time: 0.07638216018676758 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# a8a dataset"
      ],
      "metadata": {
        "id": "8sc8Z_mWgtQk"
      },
      "id": "8sc8Z_mWgtQk"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "# Load the dataset from the LIBSVM format file\n",
        "X, y = load_svmlight_file('/content/drive/MyDrive/ml_data/a8a.t')\n",
        "\n",
        "# Convert to dense format as many scikit-learn estimators expect dense format\n",
        "X_dense = X.toarray()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def predict_NSSVM(X, model_output):\n",
        "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
        "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
        "    b = model_output['w'][-1]\n",
        "    return np.sign(X.dot(w) + b)\n",
        "\n",
        "# Timing the NSSVM training\n",
        "start_time = time.time()\n",
        "\n",
        "# Run NSSVM on the training data\n",
        "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
        "\n",
        "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
        "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
        "\n",
        "# Calculate and print accuracies\n",
        "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
        "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(\"Model weights:\", model_output['w'])\n",
        "print(\"Final Training Accuracy:\", train_accuracy)\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "print(\"Total iterations:\", model_output['iter'])\n",
        "print(\"Training time:\", elapsed_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DdZflDdf9ki",
        "outputId": "b09e26e8-cfc4-4c6b-e1e6-3084e44852ce"
      },
      "id": "5DdZflDdf9ki",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NSSVM ......\n",
            "------------------------------------------\n",
            "  Iter          Error           Accuracy  \n",
            "------------------------------------------\n",
            "    1          4.59e-03         0.76026\n",
            "    2          2.17e+00         0.82691\n",
            "    3          8.37e-01         0.82970\n",
            "    4          1.11e-01         0.83147\n",
            "    5          7.65e-02         0.82970\n",
            "    6          9.41e-01         0.83084\n",
            "    7          6.45e-02         0.83996\n",
            "    8          6.70e-01         0.84136\n",
            "    9          2.23e-02         0.84187\n",
            "   10          2.87e-01         0.84326\n",
            "   11          2.21e-01         0.84453\n",
            "   12          5.11e-02         0.84503\n",
            "   13          1.23e-01         0.84415\n",
            "   14          2.48e-02         0.84503\n",
            "   15          5.79e-03         0.84579\n",
            "   16          1.54e-01         0.84503\n",
            "   17          2.95e-02         0.84554\n",
            "   18          5.58e-02         0.84554\n",
            "   19          1.56e-27         0.84592\n",
            "   20          6.57e-28         0.84592\n",
            "------------------------------------------\n",
            "Training complete.\n",
            "Model weights: [-1.04143797e-01 -6.13571653e-02  3.53558631e-02  7.02103474e-02\n",
            "  5.54895421e-02  2.24959787e-02 -2.06075451e-02  1.40378558e-02\n",
            "  2.91607295e-02 -8.27883252e-03 -8.00628892e-03 -1.15393806e-14\n",
            "  1.38340830e-02 -1.27385851e-02 -7.93622451e-03  1.47891861e-02\n",
            " -3.79782754e-03  9.63514496e-03  2.80215521e-02  5.93753615e-04\n",
            " -2.35312393e-02 -1.70143782e-02  3.98245820e-02  1.59693342e-02\n",
            "  3.40514764e-03 -2.52058674e-02 -4.35399305e-02  7.16034513e-03\n",
            "  3.02534022e-02 -3.26438785e-02 -3.92529397e-02  3.84392229e-02\n",
            " -5.59910145e-03 -1.27702656e-02 -6.76159735e-02 -1.70143782e-02\n",
            "  5.93753615e-04  1.34455739e-02  6.19369475e-02  1.45653503e-01\n",
            " -4.31928809e-02 -8.42100359e-02 -4.31047154e-02 -7.22062535e-03\n",
            " -9.17218541e-02  3.91647475e-03  1.97623421e-02  1.88534342e-02\n",
            " -1.05707315e-01  3.61677992e-02  8.15788056e-02  5.37525427e-02\n",
            " -3.79996833e-02 -3.53975088e-02  1.15249810e-02 -5.93637176e-02\n",
            " -1.27277464e-02 -7.41788616e-02  3.60698025e-02 -6.98746616e-15\n",
            "  1.13300343e-01 -1.15827899e-01  2.81429126e-02  2.18014998e-02\n",
            " -2.47782215e-03 -1.66238119e-02  1.33386158e-02  1.62167286e-03\n",
            " -3.80912478e-02  1.22177168e-02 -8.45946358e-03 -6.80755879e-02\n",
            "  6.80755879e-02 -7.26294461e-02  7.26294461e-02 -3.40644540e-02\n",
            "  3.40644540e-02 -1.09092356e-01  7.95354905e-04  9.21473412e-03\n",
            "  2.11140349e-02  7.48639015e-02  1.66871096e-02  4.62161893e-04\n",
            "  1.03094238e-02  8.89728357e-03 -4.63321378e-03 -5.04765824e-04\n",
            " -1.65491457e-02  8.85788828e-03 -9.72718197e-03 -1.26619793e-02\n",
            " -1.38976876e-02  6.49145430e-04  1.75502534e-02 -1.11561229e-03\n",
            " -1.17961196e-16  4.33987771e-03  1.64818387e-02  3.39184068e-04\n",
            " -2.89217025e-02 -4.76196022e-03 -3.24072424e-02  5.27516114e-03\n",
            "  1.39382347e-02  1.41417641e-02 -1.63017366e-02 -1.90333860e-14\n",
            " -2.76435926e-02  2.87026943e-03 -5.42195236e-02 -5.42191637e-02\n",
            " -1.31422651e-14  2.99276760e-02 -7.04297731e-15 -1.06676131e-02\n",
            " -2.56739074e-16 -1.33055769e-02 -5.39944925e-03 -6.05422010e-03\n",
            " -3.56933417e-02  1.33904415e-02 -5.40814232e-01]\n",
            "Final Training Accuracy: 84.59199189052204\n",
            "Testing Accuracy: 83.98378104409528\n",
            "Total iterations: 20\n",
            "Training time: 0.22751760482788086 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# a9a dataset"
      ],
      "metadata": {
        "id": "czpW4K9CqbSH"
      },
      "id": "czpW4K9CqbSH"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "# Load the dataset from the LIBSVM format file\n",
        "X, y = load_svmlight_file('/content/drive/MyDrive/ml_data/a9a.t')\n",
        "\n",
        "# Convert to dense format as many scikit-learn estimators expect dense format\n",
        "X_dense = X.toarray()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def predict_NSSVM(X, model_output):\n",
        "    \"\"\"Predict using the model weights from NSSVM.\"\"\"\n",
        "    w = model_output['w'][:-1]  # Exclude the bias term if it's included in the weights\n",
        "    b = model_output['w'][-1]\n",
        "    return np.sign(X.dot(w) + b)\n",
        "\n",
        "# Timing the NSSVM training\n",
        "start_time = time.time()\n",
        "\n",
        "# Run NSSVM on the training data\n",
        "model_output = NSSVM(X_train_scaled, y_train, {'maxit': 1000, 'tol': 1e-6, 'C': 1.0, 'disp': True})\n",
        "\n",
        "elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = predict_NSSVM(X_train_scaled, model_output)\n",
        "y_pred_test = predict_NSSVM(X_test_scaled, model_output)\n",
        "\n",
        "# Calculate and print accuracies\n",
        "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
        "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(\"Model weights:\", model_output['w'])\n",
        "print(\"Final Training Accuracy:\", train_accuracy)\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "print(\"Total iterations:\", model_output['iter'])\n",
        "print(\"Training time:\", elapsed_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElWyp7wkhbQx",
        "outputId": "286f3bad-a9c5-44f0-9390-79952a45f864"
      },
      "id": "ElWyp7wkhbQx",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NSSVM ......\n",
            "------------------------------------------\n",
            "  Iter          Error           Accuracy  \n",
            "------------------------------------------\n",
            "    1          1.74e-04         0.76205\n",
            "    2          1.18e-01         0.79284\n",
            "    3          2.39e-02         0.76751\n",
            "    4          4.17e-03         0.78025\n",
            "    5          1.24e-03         0.77019\n",
            "    6          2.29e-04         0.75653\n",
            "    7          6.80e-04         0.73887\n",
            "    8          3.89e-05         0.74209\n",
            "    9          7.24e-06         0.73618\n",
            "   10          1.42e-07         0.75660\n",
            "   11          1.25e-30         0.75660\n",
            "------------------------------------------\n",
            "Training complete.\n",
            "Model weights: [-1.79553699e-01 -1.72668294e-02  5.93434124e-02  7.82718098e-02\n",
            "  5.42774838e-02  5.93670568e-02 -3.99475155e-02  6.75545491e-02\n",
            "  4.16260846e-02 -1.03886858e-03 -3.01977471e-02  6.38378239e-16\n",
            "  4.13731549e-16  2.15207058e-03  3.05491849e-02 -6.22002905e-03\n",
            " -3.60969062e-03 -2.30474348e-02  3.14095589e-02 -1.51488283e-02\n",
            " -2.09512919e-02 -2.34427681e-02  1.45799251e-02  5.69906199e-03\n",
            " -1.26830927e-02  7.77036865e-03 -2.73974289e-02  3.88209518e-03\n",
            "  5.75937683e-02  2.65065747e-15 -1.60234161e-02  9.06346176e-03\n",
            "  5.44009282e-15  2.25340580e-15 -2.66707109e-02 -2.34427681e-02\n",
            " -1.51488283e-02 -5.74485695e-03  6.42978036e-02  2.07472673e-01\n",
            " -1.12666965e-01 -1.38031107e-01  6.57445626e-03 -4.15124572e-02\n",
            "  5.74253364e-02  1.28022593e-15  4.98974953e-02  5.19148012e-03\n",
            " -1.14352445e-01  6.08102063e-02  1.19767730e-01  1.21888238e-01\n",
            " -1.76920909e-02 -1.42984279e-01  2.03729089e-02  1.78330646e-02\n",
            " -7.99834437e-02  2.99066327e-15  1.04053515e-03  3.81639165e-16\n",
            " -1.87183523e-02  8.14873298e-02 -5.00788007e-02  1.60450396e-04\n",
            "  1.05456021e-02 -8.73405975e-03  2.10983551e-02  6.66517723e-02\n",
            " -2.79980564e-02  3.73042098e-04 -5.45086289e-02 -5.54565738e-02\n",
            "  5.54565738e-02 -6.73800177e-02  6.73800177e-02 -5.54763073e-03\n",
            "  5.54763073e-03 -3.26962915e-02 -9.93562111e-04 -5.78715742e-03\n",
            "  4.23130577e-02  9.72826317e-03  3.03863028e-01  6.90419943e-16\n",
            "  2.31932529e-15  2.96984659e-15  1.02597999e-01  9.61274935e-02\n",
            "  8.38738801e-16  1.80758186e-15  1.39645240e-15  1.13624388e-15\n",
            "  8.56953397e-16  2.45289900e-15  1.10501885e-15  7.92768629e-16\n",
            "  1.08767162e-15  3.11016342e-02  8.39430665e-02 -3.70608788e-03\n",
            "  1.40859546e-15  7.78890841e-16  5.07049283e-02  1.39124823e-15\n",
            "  6.19621257e-02  1.20996962e-15  8.70992836e-03  8.93382590e-16\n",
            "  1.13277443e-15  1.49359691e-15  2.15452656e-15  1.06685494e-15\n",
            "  6.80011603e-16  1.61502756e-15  1.30798150e-15  1.06338549e-15\n",
            "  7.73686670e-16  4.62303806e-16  8.56953397e-16  6.25367813e-16\n",
            "  2.94452923e-03  1.23267111e-15 -1.30907283e+00]\n",
            "Final Training Accuracy: 79.28439803439802\n",
            "Testing Accuracy: 79.82806263432607\n",
            "Total iterations: 11\n",
            "Training time: 0.050057172775268555 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sonar, mines vs rocks dataset"
      ],
      "metadata": {
        "id": "c6nbjM0Cog1e"
      },
      "id": "c6nbjM0Cog1e"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define a function for predictions based on the NSSVM model output\n",
        "def predict_NSSVM(X, model_output):\n",
        "    w = model_output['w'][:-1]  # assuming last element in 'w' is the bias\n",
        "    b = model_output['w'][-1]\n",
        "    return np.sign(X.dot(w) + b)  # Apply the sign function to get binary predictions\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
        "data = pd.read_csv(url, header=None)\n",
        "\n",
        "# The last column contains labels: 'R' for rock and 'M' for mine\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Convert class labels 'R' and 'M' to -1 and 1\n",
        "y = np.where(y == 'R', -1, 1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def run_NSSVM(X_train, y_train, X_test, y_test, pars):\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Train the model\n",
        "    model_output = NSSVM(X_train_scaled, y_train, pars)\n",
        "    print(\"Training complete.\")\n",
        "    print(\"Model weights:\", model_output['w'])\n",
        "    print(\"Final Training Accuracy:\", model_output['ACC'])\n",
        "    print(\"Total iterations:\", model_output['iter'])\n",
        "    print(\"Training time:\", model_output['time'], \"seconds\")\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    predictions = predict_NSSVM(X_test_scaled, model_output)\n",
        "    test_accuracy = accuracy_score(y_test, predictions)\n",
        "    print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "    return model_output\n",
        "\n",
        "# Define parameters\n",
        "pars = {\"maxit\": 2000, \"tol\": 1e-6, \"C\": 1.0, \"disp\": True}\n",
        "\n",
        "# Run with the updated parameters and data scaling\n",
        "model_output = run_NSSVM(X_train, y_train, X_test, y_test, pars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJnzTaofoShS",
        "outputId": "c4bf13e2-6429-407b-b239-fc1908fae395"
      },
      "id": "RJnzTaofoShS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NSSVM ......\n",
            "------------------------------------------\n",
            "  Iter          Error           Accuracy  \n",
            "------------------------------------------\n",
            "    1          1.31e-02         0.51205\n",
            "    2          1.53e+01         0.87952\n",
            "    3          4.90e+00         0.90964\n",
            "    4          1.24e+00         0.92771\n",
            "    5          6.46e-01         0.90361\n",
            "    6          1.06e+00         0.89157\n",
            "    7          5.55e-01         0.92169\n",
            "    8          3.64e-02         0.92771\n",
            "    9          1.05e+00         0.90964\n",
            "   10          5.18e-01         0.93976\n",
            "   11          2.42e-02         0.94578\n",
            "   12          5.99e-04         0.93976\n",
            "   13          7.49e-04         0.93373\n",
            "   14          1.78e-02         0.93976\n",
            "   15          9.58e-01         0.92771\n",
            "   16          1.89e-02         0.96988\n",
            "   17          5.44e-30         0.96988\n",
            "------------------------------------------\n",
            "Training complete.\n",
            "Model weights: [ 0.28884869  0.08075067 -0.58507656  0.63855408 -0.1712619   0.07367058\n",
            " -0.18801916 -0.31676877  0.38202038 -0.09807146  0.22773917  0.56728722\n",
            " -0.25864816 -0.25935134  0.13452374 -0.43147254  0.04489038  0.30535472\n",
            " -0.18815243  0.33601393 -0.37441616  0.35465473  0.26122535  0.27722369\n",
            "  0.18127723 -0.21548902  0.43849536 -0.35000487  0.1626922   0.4848214\n",
            " -1.11940362  0.64138983  0.21778928 -0.20569954  0.30053177 -0.68255651\n",
            " -0.47785175  0.60637537  0.37396765 -0.57394712 -0.2051439  -0.25084181\n",
            "  0.44839197 -0.25616531  0.56920789  0.15104951  0.42512035  0.4532414\n",
            "  0.46418045 -0.76908909  0.15770926  0.06937659  0.16571777  0.2993753\n",
            " -0.09841439 -0.08060645 -0.0779761   0.28948209  0.25300015 -0.04764613\n",
            "  0.25596735]\n",
            "Final Training Accuracy: 0.9698795180722891\n",
            "Total iterations: 17\n",
            "Training time: 0 seconds\n",
            "Test accuracy: 0.7857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# heart disease dataset"
      ],
      "metadata": {
        "id": "nkwNRsxGOdsF"
      },
      "id": "nkwNRsxGOdsF"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Heart Disease dataset from UCI Repository\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "column_names = [\n",
        "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
        "    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'\n",
        "]\n",
        "data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "\n",
        "# Handle missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Convert the 'num' attribute to a binary classification target:\n",
        "# 0 means 'no presence' of heart disease, and 1-4 mean 'presence' of heart disease\n",
        "data['num'] = (data['num'] > 0).astype(int)\n",
        "\n",
        "# Convert class labels 0 to -1 for binary classification\n",
        "y = np.where(data['num'] == 0, -1, 1)\n",
        "\n",
        "# Extract features\n",
        "X = data.iloc[:, :-1].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def run_NSSVM(X_train, y_train, X_test, y_test, pars):\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Assuming NSSVM function is defined and imports are handled\n",
        "    model_output = NSSVM(X_train_scaled, y_train, pars)\n",
        "    print(\"Training complete.\")\n",
        "    print(\"Model weights:\", model_output['w'])\n",
        "    print(\"Final Accuracy:\", model_output['ACC'])\n",
        "    print(\"Total iterations:\", model_output['iter'])\n",
        "    print(\"Training time:\", model_output['time'], \"seconds\")\n",
        "\n",
        "    # Optionally evaluate on the test set\n",
        "    # predictions = predict_NSSVM(X_test_scaled, model_output['w'])\n",
        "    # test_accuracy = accuracy_score(y_test, predictions)\n",
        "    # print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "    return model_output\n",
        "\n",
        "# Define parameters\n",
        "pars = {\"maxit\": 2000, \"tol\": 1e-6, \"C\": 1.0, \"disp\": True}\n",
        "\n",
        "# Run with the updated parameters and data scaling\n",
        "model_output = run_NSSVM(X_train, y_train, X_test, y_test, pars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqmfZO94qfF0",
        "outputId": "af57dbeb-fcd2-49d2-895b-759170d24b61"
      },
      "id": "PqmfZO94qfF0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NSSVM ......\n",
            "------------------------------------------\n",
            "  Iter          Error           Accuracy  \n",
            "------------------------------------------\n",
            "    1          7.43e-02         0.52321\n",
            "    2          3.35e+01         0.83544\n",
            "    3          4.94e+00         0.84388\n",
            "    4          3.89e-02         0.84388\n",
            "    5          7.23e-04         0.84388\n",
            "    6          8.88e-02         0.84388\n",
            "    7          6.59e-09         0.84388\n",
            "------------------------------------------\n",
            "Training complete.\n",
            "Model weights: [-0.03634618  0.217803    0.11810525  0.14576381  0.10908207 -0.15354085\n",
            "  0.0742419  -0.1689725   0.17420868  0.11531894  0.07345408  0.40082847\n",
            "  0.18542649 -0.04051312]\n",
            "Final Accuracy: 0.8438818565400844\n",
            "Total iterations: 7\n",
            "Training time: 0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nkN8R8gHqepR"
      },
      "id": "nkN8R8gHqepR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCIhm4dUpavf"
      },
      "id": "OCIhm4dUpavf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}